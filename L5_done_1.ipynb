{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Этап L5"
      ],
      "metadata": {
        "id": "TsKxOdH95B_0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r9MZszsgOmoo",
        "outputId": "138b1306-be93-49dd-a6e5-e3f32798516e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lightfm\n",
            "  Downloading lightfm-1.17.tar.gz (316 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/316.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/316.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lightfm) (2.27.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.2.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (1.3.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (3.2.0)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.17-cp310-cp310-linux_x86_64.whl size=808328 sha256=bec5f5857bb720da8c47d2d888ad3d78cfb0c1ff7a4052a53fd1bca266543e2d\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/9b/7e/0b256f2168511d8fa4dae4fae0200fdbd729eb424a912ad636\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.17\n"
          ]
        }
      ],
      "source": [
        "!pip install lightfm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gc\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import load\n",
        "from tqdm import tqdm\n",
        "from random import sample\n",
        "\n",
        "from lightfm.data import Dataset\n",
        "from lightfm import LightFM\n",
        "import lightgbm as lgbm\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.metrics import ndcg_score"
      ],
      "metadata": {
        "id": "vuCmJSo0PGwn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/WB School/data.csv.gzip\"\n",
        "interactions = pd.read_csv(path, compression=\"gzip\")\n",
        "interactions[\"order_ts\"] = pd.to_datetime(interactions[\"order_ts\"])"
      ],
      "metadata": {
        "id": "ddTyDVfatRI1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "После оценки каждой модели следует перезагружать ядро."
      ],
      "metadata": {
        "id": "byBEFw_9NNLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Вспомогательные функции"
      ],
      "metadata": {
        "id": "ZKB6ZtzGPVyy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Функции для подготовки данных.\n",
        "\n",
        "Некоторые функции являются общими для всех моделей, поэтому введём их сразу. Остальные будем инициализировать по мере надобности."
      ],
      "metadata": {
        "id": "OeH8zYwG467R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `train_test()` делит выборку на обучающую и тестовую в зависимости от модели, которую будем использовать. Для бустинга обучающую выборку надо будет поделить на train/test части ещё раз. **Глобальный test отсекается по времени**."
      ],
      "metadata": {
        "id": "aw5iM6g4tmh8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test(interactions, for_boosting=False, q=0.7, threshold=\"2023-02-28 23:59:59.947831\"):\n",
        "  interactions = interactions.drop_duplicates()\n",
        "\n",
        "  # Обучающая выборка - 2 месяца, тестовая - 1 последний месяц.\n",
        "  train = interactions[interactions.order_ts <= threshold]\n",
        "  test = interactions[interactions.order_ts > threshold]\n",
        "\n",
        "  # Оставляем только \"тёплых\" пользователей и те товары, взаимодействия с которыми были в train периоде.\n",
        "  users = np.intersect1d(train.user_id.unique(), test.user_id.unique())\n",
        "  train = train[train[\"user_id\"].isin(users)]\n",
        "  test = test[test[\"user_id\"].isin(users)]\n",
        "\n",
        "  # Для гибридной модели глобальную обучающую выборку разделим на 2 части в соотношении 70:30.\n",
        "  if for_boosting == True:\n",
        "    lfm_threshold = train[\"order_ts\"].quantile(q=q, interpolation=\"nearest\")\n",
        "\n",
        "    lfm_train = train[(train[\"order_ts\"] <= lfm_threshold)]\n",
        "    lfm_pred = train[(train[\"order_ts\"] > lfm_threshold)]\n",
        "\n",
        "    users = np.intersect1d(lfm_train.user_id.unique(), lfm_pred.user_id.unique())\n",
        "\n",
        "    lfm_train = lfm_train[lfm_train[\"user_id\"].isin(users)]\n",
        "    lfm_pred = lfm_pred[lfm_pred[\"user_id\"].isin(users)]\n",
        "    test = test[test[\"user_id\"].isin(users)]\n",
        "\n",
        "    lfm_train = lfm_train.groupby([\"user_id\", \"item_id\"], as_index=False).count() \\\n",
        "        .rename(columns={\"order_ts\": \"amount\"})\n",
        "\n",
        "    lfm_pred = lfm_pred.groupby([\"user_id\", \"item_id\"], as_index=False).count() \\\n",
        "        .rename(columns={\"order_ts\": \"amount\"})\n",
        "\n",
        "    test = test.groupby([\"user_id\", \"item_id\"], as_index=False).count() \\\n",
        "        .rename(columns={\"order_ts\": \"amount\"})\n",
        "\n",
        "    return lfm_train, lfm_pred, test\n",
        "\n",
        "  elif for_boosting == False:\n",
        "    train = train.groupby([\"user_id\", \"item_id\"], as_index=False).count() \\\n",
        "        .rename(columns={\"order_ts\": \"amount\"})\n",
        "\n",
        "    test = test.groupby([\"user_id\", \"item_id\"], as_index=False).count() \\\n",
        "        .rename(columns={\"order_ts\": \"amount\"})\n",
        "\n",
        "    return train, test"
      ],
      "metadata": {
        "id": "drxNFaFOm3E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `train_test_leave_one_out()` помещает в test последний заказ пользователей и нужна для оценки качества моделей по принципу Leave-One-Out. Параметр path указывает путь к файлу, в котором хранятся user_id пользователей, которые вошли в тестовую выборку при оценке качества на отложенном месяце."
      ],
      "metadata": {
        "id": "ex0zXrtHiIQF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_leave_one_out(interactions, path=\"/content/drive/MyDrive/WB School/L4/users.npy\", q=0.7):\n",
        "\n",
        "  interactions_temporary = interactions.groupby(\"user_id\", as_index=False)[\"order_ts\"].max().rename(columns={\"order_ts\": \"last_order_ts\"})\n",
        "  interactions = pd.merge(\n",
        "      interactions,\n",
        "      interactions_temporary,\n",
        "      on=\"user_id\",\n",
        "      how=\"left\"\n",
        "  )\n",
        "\n",
        "  test = interactions[interactions[\"order_ts\"] == interactions[\"last_order_ts\"]].drop_duplicates(subset=[\"user_id\"]).drop(columns=[\"last_order_ts\"])\n",
        "  train = interactions[~interactions.index.isin(test.index)].drop(columns=[\"last_order_ts\"])\n",
        "\n",
        "  lfm_threshold = train[\"order_ts\"].quantile(q=q, interpolation=\"nearest\")\n",
        "\n",
        "  lfm_train = train[(train[\"order_ts\"] <= lfm_threshold)]\n",
        "  lfm_pred = train[(train[\"order_ts\"] > lfm_threshold)]\n",
        "\n",
        "  users = load(path, allow_pickle=True)\n",
        "\n",
        "  lfm_train = lfm_train[lfm_train[\"user_id\"].isin(users)]\n",
        "  lfm_pred = lfm_pred[lfm_pred[\"user_id\"].isin(users)]\n",
        "  test = test[test[\"user_id\"].isin(users)]\n",
        "\n",
        "  users = np.intersect1d(lfm_train.user_id.unique(), lfm_pred.user_id.unique())\n",
        "  users = np.intersect1d(users, test.user_id.unique())\n",
        "\n",
        "  lfm_train = lfm_train[lfm_train[\"user_id\"].isin(users)]\n",
        "  lfm_pred = lfm_pred[lfm_pred[\"user_id\"].isin(users)]\n",
        "  test = test[test[\"user_id\"].isin(users)]\n",
        "\n",
        "  lfm_train = lfm_train.groupby([\"user_id\", \"item_id\"], as_index=False).count() \\\n",
        "      .rename(columns={\"order_ts\": \"amount\"})\n",
        "\n",
        "  lfm_pred = lfm_pred.groupby([\"user_id\", \"item_id\"], as_index=False).count() \\\n",
        "      .rename(columns={\"order_ts\": \"amount\"})\n",
        "\n",
        "  test = test.groupby([\"user_id\", \"item_id\"], as_index=False).count() \\\n",
        "      .rename(columns={\"order_ts\": \"amount\"})\n",
        "\n",
        "  return lfm_train, lfm_pred, test"
      ],
      "metadata": {
        "id": "np3AkiXth_Bc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `lists_to_arrays()` преобразует данные к нужному для вычисления метрик виду."
      ],
      "metadata": {
        "id": "R11-ixnL9BzE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def lists_to_arrays(ranks, relevances, recommended_items_ids, relevant_items_ids):\n",
        "  ranks_array = list()\n",
        "  relevances_array = list()\n",
        "  recommended_items_ids_array = list()\n",
        "  relevant_items_ids_array = list()\n",
        "\n",
        "  for i in tqdm(range(len(ranks))):\n",
        "    rank = np.array(ranks[i]).astype(float)\n",
        "    ranks_array.append(rank)\n",
        "\n",
        "    rel = np.array(relevances[i]).astype(int)\n",
        "    relevances_array.append(rel)\n",
        "\n",
        "    rec_items = np.array(recommended_items_ids[i]).astype(int)\n",
        "    recommended_items_ids_array.append(rec_items)\n",
        "\n",
        "    rel_items = np.array(relevant_items_ids[i]).astype(int)\n",
        "    relevant_items_ids_array.append(rel_items)\n",
        "\n",
        "  ranks_array = np.array(ranks_array)\n",
        "  relevances_array = np.array(relevances_array)\n",
        "  recommended_items_ids_array = np.array(recommended_items_ids_array)\n",
        "  relevant_items_ids_array = np.array(relevant_items_ids_array)\n",
        "\n",
        "  return ranks_array, relevances_array, recommended_items_ids_array, relevant_items_ids_array"
      ],
      "metadata": {
        "id": "8JwlAXqR9MZB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `extract_vectors()` достаёт векторы рангов, релевантностей, id рекомендованных товаров и id релевантных товаров из результирующего на предыдущем шаге датафрейма, а затем преобразует к нужному для вычисления метрик формату."
      ],
      "metadata": {
        "id": "QvFEmb5r-KfS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_vectors(predictions, test, rank_column_name=\"rank\"):\n",
        "\n",
        "  ranks = predictions.groupby(\"user_id\")[rank_column_name].apply(list).values\n",
        "  relevances = predictions.groupby(\"user_id\")[\"relevance\"].apply(list).values\n",
        "  recommended_items_ids = predictions.groupby(\"user_id\")[\"item_id\"].apply(list).values\n",
        "  relevant_items_ids = test.groupby(\"user_id\")[\"item_id\"].apply(list).values\n",
        "\n",
        "  ranks, relevances, recommended_items_ids, relevant_items_ids = lists_to_arrays(\n",
        "      ranks,\n",
        "      relevances,\n",
        "      recommended_items_ids,\n",
        "      relevant_items_ids\n",
        "  )\n",
        "  return ranks, relevances, recommended_items_ids, relevant_items_ids"
      ],
      "metadata": {
        "id": "dBXs2lmig3r5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `drop_outlier_items()` исключает из выборки самые популярные товары."
      ],
      "metadata": {
        "id": "xJQNIr87IseD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_outlier_items(df, k=20):\n",
        "  items_df = df.drop(columns=\"order_ts\").groupby(\"item_id\", as_index=False) \\\n",
        "        .count().rename(columns={\"user_id\": \"amount\"}).sort_values(\"amount\", ascending=False)\n",
        "  items = list(items_df.item_id.values[:k])\n",
        "  df = df[~df[\"item_id\"].isin(items)]\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "0-WNFLrQIiFi"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Функции для вычисления метрик"
      ],
      "metadata": {
        "id": "hgjXwghu4FxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MAP@k"
      ],
      "metadata": {
        "id": "7yek5Jfv4QLs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `user_precision()` вычисляет значение AveragePrecision@k для одного пользователя и нужна для вычисления MeanAveragePrecision@k."
      ],
      "metadata": {
        "id": "KDBBvCyx4PY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def user_average_precision(user_relevances, k=20):\n",
        "  if user_relevances[:k].sum() == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    # Считаем значение Average Precision@k для одного пользовтаеля.\n",
        "    average_precision_list = list()\n",
        "\n",
        "    for k_items in range(1, (k + 1)):\n",
        "      precision = user_relevances[:k_items].sum()\n",
        "      precision /= len(user_relevances[:k_items])\n",
        "      average_precision_list.append(precision)\n",
        "\n",
        "    average_precision_array = np.array(average_precision_list)\n",
        "    average_precision = average_precision_array * user_relevances[:k]\n",
        "    average_precision = average_precision.sum()\n",
        "    average_precision /= user_relevances[:k].sum()\n",
        "\n",
        "    return average_precision"
      ],
      "metadata": {
        "id": "I7fs8DEw4KIN"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `get_map()` считает MeanAveragePrecision@k."
      ],
      "metadata": {
        "id": "KNMiPBGg4KIN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_map(relevances, k=20):\n",
        "  mean_average_precision = 0\n",
        "  n = len(relevances)\n",
        "\n",
        "  for i in tqdm(range(n)):\n",
        "    average_precision = user_average_precision(relevances[i], k)\n",
        "    mean_average_precision += average_precision\n",
        "\n",
        "  return mean_average_precision / n"
      ],
      "metadata": {
        "id": "9c9fcXag4KIN"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MAR@k"
      ],
      "metadata": {
        "id": "sNgsLDlp4VSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `eval_single()` считает значение Recal@k для одного пользователя."
      ],
      "metadata": {
        "id": "Gmf8yaUm4KIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_single(recommended_items_ids, relevant_items_ids, k=20):\n",
        "  recall_at_k = sum(\n",
        "      [\n",
        "          1\n",
        "          for rec_item in recommended_items_ids[:k]\n",
        "          if rec_item in relevant_items_ids\n",
        "      ]\n",
        "  ) / min(len(relevant_items_ids), k)\n",
        "\n",
        "  return recall_at_k"
      ],
      "metadata": {
        "id": "jfRXpX0z4KIO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `user_average_recall()` считает AverageRecall@k одного пользователя."
      ],
      "metadata": {
        "id": "hJDPS9yN4KIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def user_average_recall(user_relevances_recommended, recommended_items_ids, relevant_items_ids, k=20):\n",
        "  if user_relevances_recommended[:k].sum() == 0:\n",
        "    return 0\n",
        "  else:\n",
        "    average_recall_list = list()\n",
        "\n",
        "    for k_items in range(1, (k + 1)):\n",
        "      recall_at_k = eval_single(recommended_items_ids, relevant_items_ids, k_items)\n",
        "      average_recall_list.append(recall_at_k)\n",
        "\n",
        "    average_recall_array = np.array(average_recall_list)\n",
        "    average_recall_array = average_recall_array * user_relevances_recommended[:k]\n",
        "    average_recall = average_recall_array.sum()\n",
        "    average_recall /= min(len(relevant_items_ids), k)\n",
        "\n",
        "    return average_recall"
      ],
      "metadata": {
        "id": "SXY_alIe4KIO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `get_mar()` считает MeanAverageRecall@k."
      ],
      "metadata": {
        "id": "7OnCDdp-4KIO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_mar(relevances_recommended, recommended_items_ids, relevant_items_ids, k=20):\n",
        "  mean_average_recall = 0\n",
        "  n = len(relevances_recommended)\n",
        "\n",
        "  for i in tqdm(range(n)):\n",
        "    average_recall = user_average_recall(relevances_recommended[i], recommended_items_ids[i], relevant_items_ids[i], k)\n",
        "    mean_average_recall += average_recall\n",
        "\n",
        "  return mean_average_recall / n"
      ],
      "metadata": {
        "id": "_p3PKc5K4KIP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NDCG@k"
      ],
      "metadata": {
        "id": "aaMy9ur94Y_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_ndcg(ranks_array, relevances_array, is_higher_better=False, k=20):\n",
        "  n = len(ranks_array)\n",
        "  ndcg = 0\n",
        "\n",
        "  # Если на вход подаются скоры, а не ранги, то необходимо указать параметр is_higher_better = True.\n",
        "  if is_higher_better == False:\n",
        "    for i in tqdm(range(n)):\n",
        "      rank = k - ranks_array[i]\n",
        "      ndcg += ndcg_score([relevances_array[i]], [rank], k=k)\n",
        "    return ndcg / n\n",
        "\n",
        "  elif is_higher_better == True:\n",
        "    for i in tqdm(range(n)):\n",
        "      ndcg += ndcg_score([relevances_array[i]], [ranks_array[i]], k=k)\n",
        "    return ndcg / n"
      ],
      "metadata": {
        "id": "zRWTL6tg4uQw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### HitRate@k"
      ],
      "metadata": {
        "id": "t14pOgq91Wq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_hit_rate(relevances_array, k=20):\n",
        "    hit_rate = 0\n",
        "    n = len(relevances_array)\n",
        "    for i in tqdm(range(n)):\n",
        "        hit_rate += relevances_array[i][:k].sum() / k\n",
        "    hit_rate /= n\n",
        "\n",
        "    return hit_rate"
      ],
      "metadata": {
        "id": "Bjas8quj1cHd"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4 в 1"
      ],
      "metadata": {
        "id": "ZOliQlWi6lJ9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `get_metrics()` считает MAP@k, MAR@k и NDCG@k модели. Выдаёт словарь, где ключи - названия метрик, значения - метрики."
      ],
      "metadata": {
        "id": "akb_FLop6o8f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_metrics(ranks, relevances, recommended_items_ids, relevant_items_ids, is_higher_better=False, k=20):\n",
        "  metrics = dict()\n",
        "\n",
        "  key = \"MAP@\" + str(k)\n",
        "  metrics[key] = get_map(relevances, k)\n",
        "\n",
        "  key = \"MAR@\" + str(k)\n",
        "  metrics[key] = get_mar(relevances, recommended_items_ids, relevant_items_ids, k)\n",
        "\n",
        "  key = \"NDCG@\" + str(k)\n",
        "  metrics[key] = get_ndcg(ranks, relevances, is_higher_better, k)\n",
        "\n",
        "  key = \"HitRate@\" + str(k)\n",
        "  metrics[key] = get_hit_rate(relevances, k)\n",
        "\n",
        "  return metrics"
      ],
      "metadata": {
        "id": "dwEttUZI6oMx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Popularity Based Recommender"
      ],
      "metadata": {
        "id": "u-BHDbVcTmuv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для модели популярных товаров разбить на train/test, надо иначе, чем для других моделей."
      ],
      "metadata": {
        "id": "bT9IDEBTwAOU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_popular(interactions, threshold=\"2023-02-28 23:59:59.947831\", path=\"/content/drive/MyDrive/WB School/L4/users.npy\"):\n",
        "  train = interactions[interactions.order_ts <= threshold]\n",
        "  test = interactions[interactions.order_ts > threshold]\n",
        "\n",
        "  users = load(path, allow_pickle=True)\n",
        "\n",
        "  train = train[train[\"user_id\"].isin(users)]\n",
        "  test = test[test[\"user_id\"].isin(users)]\n",
        "\n",
        "  return train, test"
      ],
      "metadata": {
        "id": "jARyO9Ls7T6d"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_popular(interactions)"
      ],
      "metadata": {
        "id": "uiAyioFgv_RI"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для Leave-One-Out."
      ],
      "metadata": {
        "id": "IUwGzlyK4MnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_popular_loo(interaction, path=\"/content/drive/MyDrive/WB School/L4/users.npy\"):\n",
        "  interactions_temporary = interaction.groupby(\"user_id\", as_index=False)[\"order_ts\"].max().rename(columns={\"order_ts\": \"last_order_ts\"})\n",
        "  interactions_full = pd.merge(\n",
        "      interactions,\n",
        "      interactions_temporary,\n",
        "      on=\"user_id\",\n",
        "      how=\"left\"\n",
        "  )\n",
        "\n",
        "  test = interactions_full[interactions_full[\"order_ts\"] == interactions_full[\"last_order_ts\"]].drop_duplicates(subset=[\"user_id\"]).drop(columns=[\"last_order_ts\"])\n",
        "  train = interactions_full[~interactions_full.index.isin(test.index)].drop(columns=[\"last_order_ts\"])\n",
        "\n",
        "  users = load(path, allow_pickle=True)\n",
        "\n",
        "  train = train[train[\"user_id\"].isin(users)]\n",
        "  test = test[test[\"user_id\"].isin(users)]\n",
        "\n",
        "  return train, test"
      ],
      "metadata": {
        "id": "xRGP-Gog4QLM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_popular_loo(interactions)"
      ],
      "metadata": {
        "id": "oGqIcR6e4fZ2"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `predict_popular()` рекомендует товары на основе их популярности. Сначала всем пользователям рекомендуются преобретёнными в train периоде товары. Затем, если пользователь в течение train периода заказал менее k товаров, список дополняется соотствующим количеством товаров, наиболее популярных среди пользователей train периода."
      ],
      "metadata": {
        "id": "malKGgYZYY6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_popular(train, test, k=20):\n",
        "\n",
        "  # Приготовим k наиболее популярных товаров среди всех пользователей train периода.\n",
        "  train_items = train.drop(columns=\"order_ts\").groupby(\"item_id\", as_index=False) \\\n",
        "      .count().rename(columns={\"user_id\": \"amount\"}).sort_values(\"amount\", ascending=False)\n",
        "  items = list(train_items.item_id.values[:k])\n",
        "\n",
        "  # Заполняем списки рекомендаций пользователей наиболее популярными\n",
        "  # товарами среди всех пользователей train периода.\n",
        "  predictions_dict = dict()\n",
        "  users = test[\"user_id\"].unique()\n",
        "  for user in tqdm(users):\n",
        "    predictions_dict[user] = items\n",
        "\n",
        "  # На основе построенного словаря с рекомедациями составляем датафрейм.\n",
        "  predictions_df = pd.DataFrame({\"user_id\": users})\n",
        "  predictions_df[\"item_id\"] = predictions_dict.values()\n",
        "  predictions_df = predictions_df.explode(\"item_id\")\n",
        "  predictions_df[\"rank\"] = predictions_df.groupby(\"user_id\").cumcount() + 1\n",
        "\n",
        "  test = test.groupby([\"user_id\", \"item_id\"], as_index=False).count() \\\n",
        "      .rename(columns={\"order_ts\": \"amount\"})\n",
        "  test = test.drop(columns=\"amount\")\n",
        "  test[\"relevance\"] = 1\n",
        "\n",
        "  predictions_df = pd.merge(predictions_df, test, on=[\"user_id\", \"item_id\"], how=\"left\")\n",
        "  predictions_df[\"relevance\"] = predictions_df[\"relevance\"].fillna(0)\n",
        "  predictions_df[\"relevance\"] = predictions_df[\"relevance\"].astype(int)\n",
        "\n",
        "  return predictions_df, test"
      ],
      "metadata": {
        "id": "e5XebQblRksO"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions, test = predict_popular(train, test, k=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9216a61a-35fa-48f5-8a4d-19e219473986",
        "id": "PDvqHtgkAGUs"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 514071/514071 [00:00<00:00, 1122301.15it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ranks_array, relevances_array, recommended_items_ids_array, relevant_items_ids_array = extract_vectors(predictions, test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oAkBptYrAeqP",
        "outputId": "f59bf64e-8507-4479-affb-968585c57f60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 514071/514071 [00:07<00:00, 64977.92it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На отложенном месяце:"
      ],
      "metadata": {
        "id": "xHx8oklm5cbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_metrics(\n",
        "    ranks_array,\n",
        "    relevances_array,\n",
        "    recommended_items_ids_array,\n",
        "    relevant_items_ids_array,\n",
        "    is_higher_better=False,\n",
        "    k=20\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oM3rdKXF3Q0L",
        "outputId": "b5ebb9ef-4b93-4404-9f1e-f4e826e8a9e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 514071/514071 [00:34<00:00, 14721.37it/s]\n",
            "100%|██████████| 514071/514071 [06:23<00:00, 1339.26it/s]\n",
            "100%|██████████| 514071/514071 [03:53<00:00, 2201.10it/s]\n",
            "100%|██████████| 514071/514071 [00:02<00:00, 240339.42it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MAP@20': 0.11347279871752354,\n",
              " 'MAR@20': 0.047801159744033185,\n",
              " 'NDCG@20': 0.20017988942199585,\n",
              " 'HitRate@20': 0.03948854753544846}"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Leave-One-Out:"
      ],
      "metadata": {
        "id": "Wj__tBhS5fsq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_metrics(\n",
        "    ranks_array,\n",
        "    relevances_array,\n",
        "    recommended_items_ids_array,\n",
        "    relevant_items_ids_array,\n",
        "    is_higher_better=False,\n",
        "    k=20\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edc6ee7f-52c2-461a-8562-9318e4081d94",
        "id": "mnMy2pLU-Rj2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100%|██████████| 514071/514071 [00:34<00:00, 14721.37it/s]\n",
            "100%|██████████| 514071/514071 [06:23<00:00, 1339.26it/s]\n",
            "100%|██████████| 514071/514071 [03:53<00:00, 2201.10it/s]\n",
            "100%|██████████| 514071/514071 [00:02<00:00, 240339.42it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MAP@20': 0.023951820384126632,\n",
              " 'MAR@20': 0.11467679217154712,\n",
              " 'NDCG@20': 0.04335099350809282,\n",
              " 'HitRate@20': 0.005733839608581156}"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LFM + LGBM"
      ],
      "metadata": {
        "id": "2bcTobRoHGfI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Несколько вспомогательных функций"
      ],
      "metadata": {
        "id": "ipJce3w-jjZL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `transform_interactions()` понадобится для преобразования данных."
      ],
      "metadata": {
        "id": "INeyTVj2jlPY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_interactions(interactions_grouped):\n",
        "  return interactions_grouped[[\"user_id\", \"item_id\", \"amount\"]].itertuples(index=False)"
      ],
      "metadata": {
        "id": "Zmc7erOFjkgS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `make_dataset()` преобразует исходные данные к LightFM.Dataset формату и создаёт отображение для оценки качества LightFM моделей."
      ],
      "metadata": {
        "id": "hwBdgnreimGm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dataset(train, test):\n",
        "  # Создаём обучающий и тестовый датасеты.\n",
        "  user_ids_buffered = (x for x in train[\"user_id\"].unique())\n",
        "  item_ids_buffered = (x for x in train[\"item_id\"].unique())\n",
        "\n",
        "  dataset = Dataset()\n",
        "\n",
        "  dataset.fit(\n",
        "    users=user_ids_buffered,\n",
        "    items=item_ids_buffered\n",
        "  )\n",
        "\n",
        "  interaction_matrix_train, _ = dataset.build_interactions(\n",
        "      transform_interactions(train))\n",
        "\n",
        "  # Сохраняем отображение.\n",
        "  lightfm_mapping = dataset.mapping()\n",
        "  lightfm_mapping = {\"users_mapping\": lightfm_mapping[0],\n",
        "                     \"items_mapping\": lightfm_mapping[2]}\n",
        "\n",
        "  lightfm_mapping[\"users_inv_mapping\"] = {v: k for k, v in lightfm_mapping[\"users_mapping\"].items()}\n",
        "  lightfm_mapping[\"items_inv_mapping\"] = {v: k for k, v in lightfm_mapping[\"items_mapping\"].items()}\n",
        "\n",
        "  all_cols = list(lightfm_mapping[\"items_mapping\"].values())\n",
        "\n",
        "  return interaction_matrix_train, lightfm_mapping, all_cols"
      ],
      "metadata": {
        "id": "R2mEjuNUieDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `generate_lightfm_recs_mapper()` является вспомогательной для функции отбора кандидатов от модели, следующей за ней."
      ],
      "metadata": {
        "id": "otG-Vplc0bL_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_lightfm_recs_mapper(model, item_ids, known_items, user_features, item_features, N, user_mapping, item_inv_mapping, num_threads=4):\n",
        "  def _recs_mapper(user):\n",
        "    user_id = user_mapping[user]\n",
        "    recs = model.predict(user_id, item_ids, user_features=user_features, item_features=item_features, num_threads=num_threads)\n",
        "\n",
        "    additional_N = len(known_items[user_id]) if user_id in known_items else 0\n",
        "    total_N = N + additional_N\n",
        "    top_cols = np.argpartition(recs, -np.arange(total_N))[-total_N:][::-1]\n",
        "\n",
        "    final_recs = [item_inv_mapping[item] for item in top_cols]\n",
        "    if additional_N > 0:\n",
        "      filter_items = known_items[user_id]\n",
        "      final_recs = [item for item in final_recs if item not in filter_items]\n",
        "    return final_recs[:N]\n",
        "  return _recs_mapper"
      ],
      "metadata": {
        "id": "TWZ1inDR0cbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `predict_lightfm()` составляет рекомендации для пользователей из test периода на основе обученной LightFM-модели и проставляет соответствующие значения релевантности."
      ],
      "metadata": {
        "id": "HTO0Hgi8zisx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_lightfm(model, train, test, all_cols, lightfm_mapping, top_N=20, relevances_needed=True):\n",
        "\n",
        "  # Создаём датафрейм, в котором будут храниться рекомендации для пользователей.\n",
        "  predictions = pd.DataFrame({\"user_id\": test[\"user_id\"].unique()})\n",
        "  predictions = predictions[predictions[\"user_id\"].isin(train[\"user_id\"].unique())]\n",
        "  known_items = train.groupby(\"user_id\")[\"item_id\"].apply(list).to_dict()\n",
        "\n",
        "  # Собираем предсказания\n",
        "  mapper = generate_lightfm_recs_mapper(\n",
        "    model,\n",
        "    item_ids=all_cols,\n",
        "    known_items=known_items,\n",
        "    N=top_N,\n",
        "    user_features=None,\n",
        "    item_features=None,\n",
        "    user_mapping=lightfm_mapping[\"users_mapping\"],\n",
        "    item_inv_mapping=lightfm_mapping[\"items_inv_mapping\"],\n",
        "    num_threads=20\n",
        "  )\n",
        "\n",
        "  predictions[\"item_id\"] = predictions[\"user_id\"].map(mapper)\n",
        "  predictions = predictions.explode(\"item_id\").reset_index(drop=True)\n",
        "  predictions[\"rank\"] = predictions.groupby(\"user_id\").cumcount() + 1\n",
        "\n",
        "  if relevances_needed == True:\n",
        "    test = test.drop(columns=\"amount\")\n",
        "    test[\"relevance\"] = 1\n",
        "    predictions = pd.merge(predictions, test, on=[\"user_id\", \"item_id\"], how=\"left\")\n",
        "    predictions[\"relevance\"] = predictions[\"relevance\"].fillna(0)\n",
        "    predictions[\"relevance\"] = predictions[\"relevance\"].astype(int)\n",
        "\n",
        "    return predictions\n",
        "\n",
        "  elif relevances_needed == False:\n",
        "    return predictions"
      ],
      "metadata": {
        "id": "o_ItNmq1oYla"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Обучение бустинга"
      ],
      "metadata": {
        "id": "NkckUwPgNwip"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подготовим данные для обучения 2 моделей отбора кандидатов. Для оценки качества можно пойти двумя путями.\n",
        "\n",
        "Если использовать функцию `train_test()`, то в test будут помещены все взаимодействия за 3-ий месяц."
      ],
      "metadata": {
        "id": "D7TQY8kutgdH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lfm_train, lfm_pred, test = train_test(interactions, for_boosting=True)"
      ],
      "metadata": {
        "id": "nVxxxgjrlmNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Если же вызвать функцию `train_test_leave_one_out()`, то разбиение на train будет по прицнипу Leave-One-Out и в test окажутся последний взаимодействия выборки пользователей."
      ],
      "metadata": {
        "id": "mTBzdXyGkFsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lfm_train, lfm_pred, test = train_test_leave_one_out(interactions)"
      ],
      "metadata": {
        "id": "WituZ_1yka-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразуем данные к формату `LightFM.Dataset`."
      ],
      "metadata": {
        "id": "ObHQEwV5lDAe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "interaction_matrix_train, lightfm_mapping, all_cols = make_dataset(lfm_train, lfm_pred)"
      ],
      "metadata": {
        "id": "DX0RmJrctcsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим LightFM-модели. Параметры заранее подобраны кросс-валидацией. Число скрытых факторов `no_components` выбрано в том числе и с точки зрения скорости/cложности вычислений."
      ],
      "metadata": {
        "id": "I03J0EohtpOY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_warp_kos = LightFM(\n",
        "    no_components=100,\n",
        "    k=3,\n",
        "    n=11,\n",
        "    learning_schedule=\"adagrad\",\n",
        "    loss=\"warp-kos\",\n",
        "    learning_rate=0.027,\n",
        "    item_alpha=0.00001,\n",
        "    user_alpha=0.00014,\n",
        "    max_sampled=90)\n",
        "\n",
        "model_warp_kos.fit(interaction_matrix_train, epochs=20)"
      ],
      "metadata": {
        "id": "ckV8HcT7lYcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_warp = LightFM(\n",
        "    no_components=100,\n",
        "    learning_schedule=\"adagrad\",\n",
        "    loss=\"warp\",\n",
        "    learning_rate=0.04,\n",
        "    item_alpha=0.0001,\n",
        "    user_alpha=0.00005,\n",
        "    max_sampled=90\n",
        ")\n",
        "\n",
        "model_warp.fit(interaction_matrix_train, epochs=20)"
      ],
      "metadata": {
        "id": "Pigv2LKdtuw9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a704acda-728d-4afe-fae7-6b1ae3703181"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x78138dc77550>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модели матричной факторизации склонны к переобучению под популярные товары, поэтому для сохранения разнообразия смешения айтемов, полученные в LightFM-модели, необходимо занулить."
      ],
      "metadata": {
        "id": "F63QVmV3vWdN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_warp_kos.item_biases = np.zeros_like(model_warp_kos.item_biases)\n",
        "model_warp.item_biases = np.zeros_like(model_warp.item_biases)"
      ],
      "metadata": {
        "id": "pYT18206t_T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `candidates_relevances()` объединяет кандидатов от LightFM-моделей первого уровня и проставляет значения релевантности."
      ],
      "metadata": {
        "id": "puodIwvcADsi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def candidates_relevances(model_first, model_second, lfm_train, lfm_pred, test, all_cols, lightfm_mapping, top_N=30):\n",
        "  # Отбираем кандидатов\n",
        "  predictions_first = predict_lightfm(\n",
        "      model_warp_kos,\n",
        "      lfm_train,\n",
        "      lfm_pred,\n",
        "      all_cols,\n",
        "      lightfm_mapping,\n",
        "      top_N=top_N,\n",
        "      relevances_needed=False\n",
        "  )\n",
        "\n",
        "  predictions_second = predict_lightfm(\n",
        "      model_warp,\n",
        "      lfm_train,\n",
        "      lfm_pred,\n",
        "      all_cols,\n",
        "      lightfm_mapping,\n",
        "      top_N=top_N,\n",
        "      relevances_needed=False\n",
        "  )\n",
        "\n",
        "  predictions_first = predictions_first.rename(columns={\"rank\": \"rank_first\"})\n",
        "  predictions_second = predictions_second.rename(columns={\"rank\": \"rank_second\"})\n",
        "\n",
        "  # Объединяем наборы кандидатов.\n",
        "  predictions_first = pd.merge(\n",
        "      predictions_first,\n",
        "      predictions_second,\n",
        "      on=[\"user_id\", \"item_id\"],\n",
        "      how=\"outer\"\n",
        "  )\n",
        "\n",
        "  # Проставляем значения релевантности.\n",
        "  test = test.drop(columns=\"amount\")\n",
        "  test[\"relevance\"] = 1\n",
        "  predictions_first = pd.merge(predictions_first, test, on=[\"user_id\", \"item_id\"], how=\"left\")\n",
        "  predictions_first[\"relevance\"] = predictions_first[\"relevance\"].fillna(0)\n",
        "  predictions_first[\"relevance\"] = predictions_first[\"relevance\"].astype(int)\n",
        "\n",
        "  return predictions_first"
      ],
      "metadata": {
        "id": "hPHht3RU-tSL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отберём по 30 кандидатов."
      ],
      "metadata": {
        "id": "_zLBwJ4XnXWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_train = candidates_relevances(\n",
        "    model_warp_kos,\n",
        "    model_warp,\n",
        "    lfm_train,\n",
        "    lfm_pred,\n",
        "    test,\n",
        "    all_cols,\n",
        "    lightfm_mapping,\n",
        "    top_N=30\n",
        ")"
      ],
      "metadata": {
        "id": "7kLburqk_6fR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f60b8ef0-6051-4296-c6d9-be085b897073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-63b6dee3084e>:27: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  predictions_first = pd.merge(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Составим датасет для обучения бустинга."
      ],
      "metadata": {
        "id": "qM_fe_TYAjD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `get_query_id()` нужна для разбиения пользователей по группам для бустинга."
      ],
      "metadata": {
        "id": "bATnNUP1KD-a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_query_id(df):\n",
        "  query_map = {}\n",
        "\n",
        "  for query_id, user_id in enumerate(df[\"user_id\"].unique()):\n",
        "    query_map[user_id] = query_id\n",
        "\n",
        "  query_id = df[\"user_id\"].map(query_map)\n",
        "\n",
        "  return query_id"
      ],
      "metadata": {
        "id": "c9KO_e87KETY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция `positive_negative_sampling()` делает семплирование релевантных и нерелевантных взаимодействий в указанном соотношении и составляет датасеты для обучения и валидации бустинга."
      ],
      "metadata": {
        "id": "U7jlVzXUBJL1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positive_negative_sampling(candidates, lfm_pred, pos_neg_ratio=0.2, val_users_size=0.3):\n",
        "  # Семплируем в требуемом соотношении.\n",
        "  pos = candidates.merge(\n",
        "      lfm_pred,\n",
        "      on=[\"user_id\", \"item_id\"],\n",
        "      how=\"inner\"\n",
        "  )\n",
        "  pos[\"target\"] = 1\n",
        "\n",
        "  neg = candidates.set_index([\"user_id\", \"item_id\"]) \\\n",
        "          .join(lfm_pred.set_index([\"user_id\", \"item_id\"]))\n",
        "  neg = neg.reset_index()\n",
        "\n",
        "  neg_sample_frac = len(pos) / (len(neg) * pos_neg_ratio)\n",
        "  neg = neg.sample(frac=neg_sample_frac)\n",
        "  neg[\"target\"] = 0\n",
        "\n",
        "  # Собираем датасеты для обучения и валидации, т.е. для механизма early_stopping.\n",
        "  train_users, val_users = train_test_split(\n",
        "      lfm_pred[\"user_id\"].unique(),\n",
        "      random_state=42,\n",
        "      test_size=val_users_size\n",
        "  )\n",
        "\n",
        "  select_col = [\"user_id\", \"item_id\", \"rank_first\", \"rank_second\", \"target\"]\n",
        "  lgbm_train = shuffle(pd.concat([pos[pos[\"user_id\"].isin(train_users)],\n",
        "                                  neg[neg[\"user_id\"].isin(train_users)]])[select_col])\n",
        "  lgbm_val = shuffle(pd.concat([pos[pos[\"user_id\"].isin(val_users)],\n",
        "                                neg[neg[\"user_id\"].isin(val_users)]])[select_col])\n",
        "\n",
        "  # Делаем разбиение по пользователям.\n",
        "  lgbm_train[\"query_id\"] = get_query_id(lgbm_train)\n",
        "  lgbm_val[\"query_id\"] = get_query_id(lgbm_val)\n",
        "\n",
        "  train_group = lgbm_train[\"query_id\"].value_counts().sort_index().values\n",
        "  val_group = lgbm_val[\"query_id\"].value_counts().sort_index().values\n",
        "\n",
        "  del lgbm_train[\"query_id\"]\n",
        "  del lgbm_val[\"query_id\"]\n",
        "  gc.collect()\n",
        "\n",
        "  # Убедимся, что с типом данных всё в порядке.\n",
        "  lgbm_train[\"item_id\"] = lgbm_train[\"item_id\"].astype(np.int64)\n",
        "  lgbm_val[\"item_id\"] = lgbm_val[\"item_id\"].astype(np.int64)\n",
        "\n",
        "  # Преобразуем данные для обучения и механизма ранней остановки к нужному для lgbm формату.\n",
        "  train_lgbm_dataset = lgbm.Dataset(\n",
        "      data=lgbm_train.drop(columns=\"target\"), label=lgbm_train[\"target\"],\n",
        "      group=train_group\n",
        "  )\n",
        "\n",
        "  val_lgbm_dataset = lgbm.Dataset(\n",
        "      data=lgbm_val.drop(columns=\"target\"), label=lgbm_val[\"target\"],\n",
        "      group=val_group\n",
        "  )\n",
        "\n",
        "  return train_lgbm_dataset, val_lgbm_dataset"
      ],
      "metadata": {
        "id": "wrVXJEHRAiak"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_lgbm_dataset, val_lgbm_dataset = positive_negative_sampling(\n",
        "    predictions_train,\n",
        "    lfm_pred,\n",
        "    pos_neg_ratio=0.2,\n",
        "    val_users_size=0.2\n",
        ")"
      ],
      "metadata": {
        "id": "XJdvM8VqMgLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del predictions_train\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "57v4lmp6WWAm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b15030e-107d-41d4-bc85-29e607226297"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим бустинг."
      ],
      "metadata": {
        "id": "YvRU6tC4MYQL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"objective\": \"lambdarank\",\n",
        "    \"learning_rate\": 0.09,\n",
        "    \"n_estimators\": 1000,\n",
        "    \"max_depth\": 35,\n",
        "    \"subsample\": 0.8,\n",
        "    \"colsample_bytree\": 0.8,\n",
        "    \"first_metric_only\": True,\n",
        "    \"metric\": (\n",
        "        \"lambdarank\", \"map\", \"auc\"\n",
        "    ),\n",
        "    \"reg_lambda\": 0.0011,\n",
        "    \"eval_at\": (20)\n",
        "}"
      ],
      "metadata": {
        "id": "XZFXAXKTNXwj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "booster = lgbm.train(\n",
        "    params=params,\n",
        "    train_set=train_lgbm_dataset,\n",
        "    num_boost_round=1600,\n",
        "    valid_sets=[train_lgbm_dataset, val_lgbm_dataset],\n",
        "    early_stopping_rounds=300,\n",
        "    verbose_eval=50\n",
        ")"
      ],
      "metadata": {
        "id": "zv-6E7JTNmCZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef3cfe42-a906-4ec1-e19f-072014f0c5dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:177: UserWarning: Found `n_estimators` in params. Will use it instead of argument\n",
            "  _log_warning(f\"Found `{alias}` in params. Will use it instead of argument\")\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n",
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Total groups: 411226, total data: 4111302\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.178311 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 594\n",
            "[LightGBM] [Info] Number of data points in the train set: 4111302, number of used features: 4\n",
            "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
            "[LightGBM] [Info] Total groups: 102805, total data: 1027896\n",
            "Training until validation scores don't improve for 300 rounds\n",
            "[50]\ttraining's ndcg@20: 0.772635\ttraining's map@20: 0.668162\ttraining's auc: 0.730176\tvalid_1's ndcg@20: 0.772809\tvalid_1's map@20: 0.668421\tvalid_1's auc: 0.731655\n",
            "[100]\ttraining's ndcg@20: 0.775754\ttraining's map@20: 0.672364\ttraining's auc: 0.735336\tvalid_1's ndcg@20: 0.775706\tvalid_1's map@20: 0.672329\tvalid_1's auc: 0.736691\n",
            "[150]\ttraining's ndcg@20: 0.777053\ttraining's map@20: 0.674105\ttraining's auc: 0.737\tvalid_1's ndcg@20: 0.776789\tvalid_1's map@20: 0.673787\tvalid_1's auc: 0.73814\n",
            "[200]\ttraining's ndcg@20: 0.777988\ttraining's map@20: 0.675337\ttraining's auc: 0.738009\tvalid_1's ndcg@20: 0.777099\tvalid_1's map@20: 0.674197\tvalid_1's auc: 0.73893\n",
            "[250]\ttraining's ndcg@20: 0.778666\ttraining's map@20: 0.676203\ttraining's auc: 0.738646\tvalid_1's ndcg@20: 0.777345\tvalid_1's map@20: 0.674542\tvalid_1's auc: 0.739373\n",
            "[300]\ttraining's ndcg@20: 0.77932\ttraining's map@20: 0.677046\ttraining's auc: 0.739148\tvalid_1's ndcg@20: 0.777472\tvalid_1's map@20: 0.674704\tvalid_1's auc: 0.739652\n",
            "[350]\ttraining's ndcg@20: 0.779951\ttraining's map@20: 0.677865\ttraining's auc: 0.739592\tvalid_1's ndcg@20: 0.777558\tvalid_1's map@20: 0.674824\tvalid_1's auc: 0.739867\n",
            "[400]\ttraining's ndcg@20: 0.78041\ttraining's map@20: 0.67846\ttraining's auc: 0.739928\tvalid_1's ndcg@20: 0.777575\tvalid_1's map@20: 0.674857\tvalid_1's auc: 0.739965\n",
            "[450]\ttraining's ndcg@20: 0.780972\ttraining's map@20: 0.679176\ttraining's auc: 0.740255\tvalid_1's ndcg@20: 0.777682\tvalid_1's map@20: 0.674983\tvalid_1's auc: 0.740073\n",
            "[500]\ttraining's ndcg@20: 0.7815\ttraining's map@20: 0.679853\ttraining's auc: 0.740557\tvalid_1's ndcg@20: 0.777642\tvalid_1's map@20: 0.674928\tvalid_1's auc: 0.74015\n",
            "[550]\ttraining's ndcg@20: 0.781968\ttraining's map@20: 0.680463\ttraining's auc: 0.7409\tvalid_1's ndcg@20: 0.777723\tvalid_1's map@20: 0.675039\tvalid_1's auc: 0.740274\n",
            "[600]\ttraining's ndcg@20: 0.782342\ttraining's map@20: 0.680941\ttraining's auc: 0.741127\tvalid_1's ndcg@20: 0.777701\tvalid_1's map@20: 0.675017\tvalid_1's auc: 0.740284\n",
            "[650]\ttraining's ndcg@20: 0.782699\ttraining's map@20: 0.681404\ttraining's auc: 0.741371\tvalid_1's ndcg@20: 0.777736\tvalid_1's map@20: 0.675044\tvalid_1's auc: 0.740342\n",
            "[700]\ttraining's ndcg@20: 0.783077\ttraining's map@20: 0.681892\ttraining's auc: 0.741663\tvalid_1's ndcg@20: 0.777758\tvalid_1's map@20: 0.675071\tvalid_1's auc: 0.740404\n",
            "[750]\ttraining's ndcg@20: 0.783443\ttraining's map@20: 0.682372\ttraining's auc: 0.741959\tvalid_1's ndcg@20: 0.777734\tvalid_1's map@20: 0.675044\tvalid_1's auc: 0.740459\n",
            "[800]\ttraining's ndcg@20: 0.783921\ttraining's map@20: 0.682994\ttraining's auc: 0.742209\tvalid_1's ndcg@20: 0.777824\tvalid_1's map@20: 0.675171\tvalid_1's auc: 0.740513\n",
            "[850]\ttraining's ndcg@20: 0.784255\ttraining's map@20: 0.683421\ttraining's auc: 0.74242\tvalid_1's ndcg@20: 0.777751\tvalid_1's map@20: 0.675073\tvalid_1's auc: 0.740538\n",
            "[900]\ttraining's ndcg@20: 0.784608\ttraining's map@20: 0.683879\ttraining's auc: 0.742619\tvalid_1's ndcg@20: 0.777741\tvalid_1's map@20: 0.67507\tvalid_1's auc: 0.740552\n",
            "[950]\ttraining's ndcg@20: 0.784922\ttraining's map@20: 0.684287\ttraining's auc: 0.742865\tvalid_1's ndcg@20: 0.777727\tvalid_1's map@20: 0.67504\tvalid_1's auc: 0.740556\n",
            "[1000]\ttraining's ndcg@20: 0.785214\ttraining's map@20: 0.684667\ttraining's auc: 0.743069\tvalid_1's ndcg@20: 0.777755\tvalid_1's map@20: 0.675093\tvalid_1's auc: 0.740567\n",
            "Did not meet early stopping. Best iteration is:\n",
            "[1000]\ttraining's ndcg@20: 0.785214\ttraining's map@20: 0.684667\ttraining's auc: 0.743069\tvalid_1's ndcg@20: 0.777755\tvalid_1's map@20: 0.675093\tvalid_1's auc: 0.740567\n",
            "Evaluated only: ndcg@20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Оценка гибридной модели"
      ],
      "metadata": {
        "id": "KKENcnPPN3ga"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отберём по 30 кандидатов для каждого пользователя для предсказания на test периоде."
      ],
      "metadata": {
        "id": "yuEPXy3OU88r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_first_test = predict_lightfm(\n",
        "    model_warp_kos,\n",
        "    lfm_train,\n",
        "    test,\n",
        "    all_cols,\n",
        "    lightfm_mapping,\n",
        "    top_N=30,\n",
        "    relevances_needed=False\n",
        ")"
      ],
      "metadata": {
        "id": "7xcQT2dGN80v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model_warp_kos\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "NF2sKkyoHWb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c296bdf0-7416-4dcf-98c2-10998ccb41f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_second_test = predict_lightfm(\n",
        "    model_warp,\n",
        "    lfm_train,\n",
        "    test,\n",
        "    all_cols,\n",
        "    lightfm_mapping,\n",
        "    top_N=30,\n",
        "    relevances_needed=False\n",
        ")"
      ],
      "metadata": {
        "id": "iIoMclb2Hatc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model_warp\n",
        "del lfm_train, all_cols, lightfm_mapping\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "60iOrLpPV-YL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7a3e081-9c57-4d25-af1d-62b0243993c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_first_test = predictions_first_test.rename(columns={\"rank\": \"rank_first\"})\n",
        "predictions_second_test = predictions_second_test.rename(columns={\"rank\": \"rank_second\"})"
      ],
      "metadata": {
        "id": "8_GjYqGcYG6n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Объединим кандидатов."
      ],
      "metadata": {
        "id": "7994FHg_HfhF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test = pd.merge(\n",
        "    predictions_first_test,\n",
        "    predictions_second_test,\n",
        "    on=[\"user_id\", \"item_id\"],\n",
        "    how=\"outer\"\n",
        ")"
      ],
      "metadata": {
        "id": "Cwfh6MucXdfx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6232844d-cdf0-42b8-ce7a-ac0c374eba0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-41-c0ccc2a80e65>:1: FutureWarning: In a future version, the Index constructor will not infer numeric dtypes when passed object-dtype sequences (matching Series behavior)\n",
            "  predictions_test = pd.merge(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test[\"item_id\"] = predictions_test[\"item_id\"].astype(np.int64)"
      ],
      "metadata": {
        "id": "XRf9HjFkKyKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del predictions_first_test, predictions_second_test, lfm_pred\n",
        "del train_test, transform_interactions, make_dataset, generate_lightfm_recs_mapper\n",
        "del predict_lightfm, candidates_relevances, get_query_id, positive_negative_sampling\n",
        "del interaction_matrix_train, interactions, params, path, train_lgbm_dataset, val_lgbm_dataset\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "fzI8DMXcYMaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67149f77-ea75-459d-a9d5-04997ca807f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Посчитаем прогнозы скоров от бустинга."
      ],
      "metadata": {
        "id": "Fqjr_2yViwJS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test[\"lgbm_pred\"] = booster.predict(predictions_test)"
      ],
      "metadata": {
        "id": "dIzl3OotivZZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del booster\n",
        "\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "bY4MF5bva6j8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e18f0e06-2769-45dc-d873-4b75325e566a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Проставим значения релевантности."
      ],
      "metadata": {
        "id": "xn_ZEd9wjc-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = test.drop(columns=\"amount\")\n",
        "test[\"relevance\"] = 1"
      ],
      "metadata": {
        "id": "Rxla7WqWbN0j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test = predictions_test.sort_values(\n",
        "    by=[\"user_id\", \"lgbm_pred\"], ascending=[True, False])"
      ],
      "metadata": {
        "id": "K_v0cH7uK5Ux"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test = pd.merge(\n",
        "    predictions_test,\n",
        "    test,\n",
        "    on=[\"user_id\", \"item_id\"],\n",
        "    how=\"left\"\n",
        ")"
      ],
      "metadata": {
        "id": "hs5aZMqajDJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test[\"relevance\"] = predictions_test[\"relevance\"].fillna(0)\n",
        "predictions_test[\"relevance\"] = predictions_test[\"relevance\"].astype(int)"
      ],
      "metadata": {
        "id": "6Yjzv2ybLAxd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Inu_ZVGNdpZU",
        "outputId": "9b81faf6-8a89-48b5-a5a6-d3cf1e89c860"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  item_id  rank_first  rank_second  lgbm_pred  relevance\n",
              "0        3       69        15.0          7.0   1.409048          0\n",
              "1        3       11         5.0          6.0   1.313342          0\n",
              "2        3      192         NaN         15.0   1.159265          0\n",
              "3        3       41         2.0         10.0   1.058938          0\n",
              "4        3      165         1.0         11.0   1.035075          0"
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-1e7479a0-b3de-4ee2-a01c-b4d5fe630d1c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>rank_first</th>\n",
              "      <th>rank_second</th>\n",
              "      <th>lgbm_pred</th>\n",
              "      <th>relevance</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>69</td>\n",
              "      <td>15.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.409048</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>11</td>\n",
              "      <td>5.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.313342</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>192</td>\n",
              "      <td>NaN</td>\n",
              "      <td>15.0</td>\n",
              "      <td>1.159265</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>41</td>\n",
              "      <td>2.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.058938</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>165</td>\n",
              "      <td>1.0</td>\n",
              "      <td>11.0</td>\n",
              "      <td>1.035075</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1e7479a0-b3de-4ee2-a01c-b4d5fe630d1c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-34fc904d-a076-4adf-adb4-7252d4bd6f55\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-34fc904d-a076-4adf-adb4-7252d4bd6f55')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-34fc904d-a076-4adf-adb4-7252d4bd6f55 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1e7479a0-b3de-4ee2-a01c-b4d5fe630d1c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1e7479a0-b3de-4ee2-a01c-b4d5fe630d1c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions_test.user_id.nunique(), predictions_test.item_id.nunique()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ace4594e-a7e9-49f6-aeec-04e5bd73582a",
        "id": "OsqimS5Vq5rf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(514071, 1728)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Достанем необходимые векторы значений."
      ],
      "metadata": {
        "id": "7xcEPq7ejqlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds_array, relevances_array, recommended_items_ids_array, relevant_items_ids_array = extract_vectors(\n",
        "    predictions_test,\n",
        "    test,\n",
        "    rank_column_name=\"lgbm_pred\"\n",
        ")"
      ],
      "metadata": {
        "id": "qrXIyNk5jbqH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "969d2cba-89d7-4964-9f87-52f38ff31459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 514071/514071 [00:18<00:00, 28294.02it/s]\n",
            "<ipython-input-5-7caced98b2e2>:20: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  ranks_array = np.array(ranks_array)\n",
            "<ipython-input-5-7caced98b2e2>:21: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  relevances_array = np.array(relevances_array)\n",
            "<ipython-input-5-7caced98b2e2>:22: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  recommended_items_ids_array = np.array(recommended_items_ids_array)\n",
            "<ipython-input-5-7caced98b2e2>:23: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  relevant_items_ids_array = np.array(relevant_items_ids_array)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Наконец, посмотрим на качество бустинга."
      ],
      "metadata": {
        "id": "9mDIwf_rNY4H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "На отложенном месяце:"
      ],
      "metadata": {
        "id": "R-M6hYe1rh0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_metrics(\n",
        "    preds_array,\n",
        "    relevances_array,\n",
        "    recommended_items_ids_array,\n",
        "    relevant_items_ids_array,\n",
        "    is_higher_better=True,\n",
        "    k=20\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l0M_dz6fLIPh",
        "outputId": "fdd87ec4-ee1a-4f68-e392-add42714c414"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 514071/514071 [00:34<00:00, 14721.37it/s]\n",
            "100%|██████████| 514071/514071 [06:23<00:00, 1339.26it/s]\n",
            "100%|██████████| 514071/514071 [03:53<00:00, 2201.10it/s]\n",
            "100%|██████████| 514071/514071 [00:02<00:00, 240339.42it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MAP@20': 0.2500176385052239,\n",
              " 'MAR@20': 0.10536632559289105,\n",
              " 'NDCG@20': 0.31910651845312094,\n",
              " 'HitRate@20': 0.08224467048326073}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "На основании LeaveOneOut-стратегии:"
      ],
      "metadata": {
        "id": "sWUSh27rrmEB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "get_metrics(\n",
        "    preds_array,\n",
        "    relevances_array,\n",
        "    recommended_items_ids_array,\n",
        "    relevant_items_ids_array,\n",
        "    is_higher_better=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "193eafc7-76e0-4dc0-bb6e-6f88ce3df604",
        "id": "xnzsez3nr1-z"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 456890/456890 [00:09<00:00, 49443.33it/s]\n",
            "100%|██████████| 456890/456890 [01:25<00:00, 5358.07it/s]\n",
            "100%|██████████| 456890/456890 [02:16<00:00, 3343.38it/s]\n",
            "100%|██████████| 456890/456890 [00:01<00:00, 428857.97it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MAP@20': 0.06629452961350915,\n",
              " 'MAR@20': 0.22583554028321914,\n",
              " 'NDCG@20': 0.10116652168922431,\n",
              " 'HitRate@20': 0.011291777014182852}"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    }
  ]
}