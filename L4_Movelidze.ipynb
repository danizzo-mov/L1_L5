{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Этап L4\n",
        "\n",
        "**Задача:** разработка бейзлайна и реализация выбранного решения.\n",
        "\n",
        "**Итог работы:** готов бейзлайн и первая реализация выбранного решения."
      ],
      "metadata": {
        "id": "t4q8QuGqSaE0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lightfm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mtKUZ1_OSfWb",
        "outputId": "60d53fb4-1163-4aa6-cd09-05a073d566bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting lightfm\n",
            "  Downloading lightfm-1.17.tar.gz (316 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.4/316.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.22.4)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.10.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from lightfm) (2.27.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from lightfm) (1.2.2)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->lightfm) (3.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->lightfm) (3.1.0)\n",
            "Building wheels for collected packages: lightfm\n",
            "  Building wheel for lightfm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lightfm: filename=lightfm-1.17-cp310-cp310-linux_x86_64.whl size=879174 sha256=5329fea634d087b7ccbe2405ad4cc791d9eed6eba23291d0b3ad377db2498524\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/9b/7e/0b256f2168511d8fa4dae4fae0200fdbd729eb424a912ad636\n",
            "Successfully built lightfm\n",
            "Installing collected packages: lightfm\n",
            "Successfully installed lightfm-1.17\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install lightgbm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_cdqnNClShi1",
        "outputId": "6b480973-a305-45d9-bc82-b56aaad28374"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (3.3.5)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from lightgbm) (0.40.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0 in /usr/local/lib/python3.10/dist-packages (from lightgbm) (1.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0->lightgbm) (3.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import load\n",
        "from scipy.sparse import csr_matrix, coo_matrix\n",
        "# from lightfm import LightFM\n",
        "from datetime import datetime\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "# import pickle\n",
        "import itertools\n",
        "import random\n",
        "import lightgbm"
      ],
      "metadata": {
        "id": "b-v2wDg6Sj5j"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/WB School/data.csv.gzip\"\n",
        "df = pd.read_csv(path, compression='gzip')\n",
        "df[\"order_ts\"] = pd.to_datetime(df[\"order_ts\"])"
      ],
      "metadata": {
        "id": "OJyaZ55FAK8X"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Предобработка данных"
      ],
      "metadata": {
        "id": "_WX_h5U2S_Q8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Отделим пользователей с малым количеством заказов. Им будут рекомендоваться популярные товары."
      ],
      "metadata": {
        "id": "2V7PRxWzThyL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_reluctant_users(df, threshold=5, both=False):\n",
        "\n",
        "  len_df = len(df)\n",
        "  df = df.drop_duplicates()\n",
        "  df_count = df.groupby([\"user_id\", \"item_id\"], as_index=False).count().rename(columns={\"order_ts\": \"counter\"})\n",
        "\n",
        "  df_count_users = df_count.groupby(\"user_id\", as_index=False)[\"counter\"].sum()\n",
        "  users = df_count_users.loc[df_count_users.counter <= threshold, \"user_id\"].values\n",
        "\n",
        "  df_reluctants = df[df.user_id.isin(users)]\n",
        "  df = df[~df.user_id.isin(users)]\n",
        "\n",
        "  if both:\n",
        "    return df_reluctants, df\n",
        "  else:\n",
        "    return df"
      ],
      "metadata": {
        "id": "6S6jDn2CTJXM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = extract_reluctant_users(df, threshold=20)"
      ],
      "metadata": {
        "id": "Z90jJx5xTgn8"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Исключим редко заказываемые товары:"
      ],
      "metadata": {
        "id": "HXcu-pv5TsRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def drop_rare_items(df, threshold=2):\n",
        "\n",
        "  df_temp = df.drop_duplicates()\n",
        "  df_count = df_temp.groupby([\"user_id\", \"item_id\"], as_index=False).count().rename(columns={\"order_ts\": \"counter\"})\n",
        "  df_count_items = df_count.groupby(\"item_id\", as_index=False)[\"counter\"].sum()\n",
        "\n",
        "  items = df_count_items.loc[df_count_items.counter <= threshold, \"item_id\"].values\n",
        "  df = df[~df.item_id.isin(items)]\n",
        "\n",
        "  return df"
      ],
      "metadata": {
        "id": "fCy57sWSTKnL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_new = drop_rare_items(df_new, threshold=10)"
      ],
      "metadata": {
        "id": "_XBv1owrTfdT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для разделения на train/test и для кросс-валидации используется схема, предложенная в [работе](https://arxiv.org/abs/1805.09557):\n",
        "\n"
      ],
      "metadata": {
        "id": "KXmnjHroUEXD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test(df, by, test_weeks=1, test_size=0.2):\n",
        "\n",
        "  if by == \"time\":\n",
        "\n",
        "    n_folds = 13 / test_weeks\n",
        "\n",
        "    delta = (df[\"order_ts\"].max() - df[\"order_ts\"].min()) / n_folds\n",
        "    edge = df[\"order_ts\"].max() - delta\n",
        "\n",
        "    train = df.loc[df[\"order_ts\"] <= edge]\n",
        "    test = df.loc[df[\"order_ts\"] > edge]\n",
        "\n",
        "    return train, test\n",
        "\n",
        "  elif by == \"percents\":\n",
        "\n",
        "    train_size = 1 - test_size\n",
        "    idx = int(len(df) * train_size)\n",
        "\n",
        "    train = df[:idx]\n",
        "    test = df[idx:]\n",
        "\n",
        "    return train, test"
      ],
      "metadata": {
        "id": "VtUr6Ik6TVOL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_global, test_global = train_test(df_new, by=\"time\", test_weeks=1)"
      ],
      "metadata": {
        "id": "EIxTG57sTWUr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оставим юзеров, которые делали заказы в течение периода и train_global, и test_global:"
      ],
      "metadata": {
        "id": "egbcpRMxasq9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def common_only(df1, df2, column=\"users\"):\n",
        "\n",
        "  users = list(set(df1[column]).intersection(set(df2[column])))\n",
        "\n",
        "  df1_new = df1[df1[column].isin(users)]\n",
        "  df2_new = df2[df2[column].isin(users)]\n",
        "\n",
        "  return df1_new, df2_new"
      ],
      "metadata": {
        "id": "Dy27exMvTbIL"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_global, test_global = common_only(train_global, test_global, column=\"user_id\")\n",
        "train_global = extract_reluctant_users(train_global)"
      ],
      "metadata": {
        "id": "yXmPtlv8bATb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Делим train_global на локальные train и test выборки:"
      ],
      "metadata": {
        "id": "l1eUVrhFbRDc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_local, test_local = train_test(train_global, by=\"percents\", test_size=0.2)\n",
        "train_local = extract_reluctant_users(train_local)\n",
        "\n",
        "train_local = drop_rare_items(train_local, threshold=20)\n",
        "\n",
        "train_local, test_local = common_only(train_local, test_local, column=\"user_id\")\n",
        "train_local, test_local = common_only(train_local, test_local, column=\"item_id\")\n",
        "\n",
        "train_local, test_local = common_only(train_local, test_local, column=\"user_id\")\n",
        "train_local, test_local = common_only(train_local, test_local, column=\"item_id\")"
      ],
      "metadata": {
        "id": "atK1pXRBbNPV"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Создадим разрезженную матрицу взаимодействий."
      ],
      "metadata": {
        "id": "dCCRcYXTmEru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def csr_matrix_via_encoder(train, test): # Датафреймы должны быть сгруппированными!\n",
        "\n",
        "  user_encoder, item_encoder = LabelEncoder(), LabelEncoder()\n",
        "\n",
        "  users_final = set(train.user_id.unique()).intersection(set(test.user_id.unique()))\n",
        "  user_encoder.fit(list(users_final))\n",
        "\n",
        "  all_items = set(train.item_id.unique()).union(set(test.item_id.unique()))\n",
        "  item_encoder.fit(list(all_items))\n",
        "\n",
        "  train[\"user_new_id\"] = user_encoder.transform(train[\"user_id\"])\n",
        "  test[\"user_new_id\"] = user_encoder.transform(test[\"user_id\"])\n",
        "\n",
        "  train[\"item_new_id\"] = item_encoder.transform(train[\"item_id\"])\n",
        "  test[\"item_new_id\"] = item_encoder.transform(test[\"item_id\"])\n",
        "\n",
        "  matrix_shape = len(user_encoder.classes_), len(item_encoder.classes_)\n",
        "\n",
        "  train_sparse = coo_matrix((list(train.counter.astype(np.float32)),\n",
        "                            (list(train.user_new_id.astype(np.int64)),\n",
        "                              list(train.item_new_id.astype(np.int64)))), shape=matrix_shape)\n",
        "\n",
        "  train_csr = train_sparse.tocsr()\n",
        "\n",
        "  test_sparse = coo_matrix((list(test.counter.astype(np.float32)),\n",
        "                           (list(test.user_new_id.astype(np.int64)),\n",
        "                            list(test.item_new_id.astype(np.int64)))), shape=matrix_shape)\n",
        "\n",
        "  test_csr = test_sparse.tocsr()\n",
        "\n",
        "  return train_csr, test_csr, users_final, all_items, train, test"
      ],
      "metadata": {
        "id": "I3ny19U8UBHj"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_local_grouped = train_local.groupby([\"user_id\", \"item_id\"], as_index=False).count().rename(columns={\"order_ts\": \"counter\"})\n",
        "test_local_grouped = test_local.groupby([\"user_id\", \"item_id\"], as_index=False).count().rename(columns={\"order_ts\": \"counter\"})\n",
        "\n",
        "train_local_grouped = train_local_grouped.sort_values(\"user_id\")\n",
        "test_local_grouped = test_local_grouped.sort_values(\"user_id\")\n",
        "\n",
        "train_local_csr, test_local_csr, users_final, all_items, train, test = csr_matrix_via_encoder(train_local_grouped, test_local_grouped)"
      ],
      "metadata": {
        "id": "ZpcRpth7l76n"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Отбор кандидатов"
      ],
      "metadata": {
        "id": "nMQBsKp7m2a2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим модели, которые будут отбирать кандидатов: [WARP loss MF](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/37180.pdf), [BPR Optimized MF](https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf), [LMF](https://web.stanford.edu/~rezab/nips2014workshop/submits/logmat.pdf) и [WARP k-OS loss MF](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41534.pdf). Их оптимальные параметры по метрике Recall@K были подобраны заранее кросс-валидацией на train_local.\n",
        "\n"
      ],
      "metadata": {
        "id": "S8PNOZMhmq72"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_warp = LightFM(no_components=16,\n",
        "                     learning_schedule=\"adagrad\",\n",
        "                     loss=\"warp\",\n",
        "                     learning_rate=0.05,\n",
        "                     item_alpha=0.00005,\n",
        "                     user_alpha=0.00005,\n",
        "                     max_sampled=30)\n",
        "\n",
        "model_warp.fit(train_local_csr, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IOjOlCZDncgm",
        "outputId": "602efd31-ad97-44bb-98b1-ba2ef44eba71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7f89509b6860>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(model_warp, open(\"model_warp_new.pkl\", \"wb\"))"
      ],
      "metadata": {
        "id": "3OajSWIH8F1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_bpr = LightFM(no_components=14,\n",
        "                    learning_schedule=\"adagrad\",\n",
        "                    loss=\"bpr\",\n",
        "                    learning_rate=0.03,\n",
        "                    item_alpha=0.00001,\n",
        "                    user_alpha=0.0001)\n",
        "\n",
        "model_bpr.fit(train_local_csr, epochs = 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJeZ96qfnhIA",
        "outputId": "3b6c69de-fe7a-44ab-b878-70d66006ebfa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7fe624042440>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(model_bpr, open(\"model_bpr.pkl\", \"wb\"))"
      ],
      "metadata": {
        "id": "se3Y2llUYHC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_lmf = LightFM(no_components=13,\n",
        "                    learning_schedule=\"adagrad\",\n",
        "                    loss=\"logistic\",\n",
        "                    learning_rate=0.019,\n",
        "                    item_alpha=0.0001,\n",
        "                    user_alpha=0.00001)\n",
        "\n",
        "model_lmf.fit(train_local_csr, epochs = 20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ljYubfPWnkpD",
        "outputId": "e91e13ba-2b67-4f86-e9fd-5ac8bdfae5e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7fe624041360>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(model_lmf, open(\"model_lmf.pkl\", \"wb\"))"
      ],
      "metadata": {
        "id": "PP2Dlx9QYPYL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_warp_kos = LightFM(no_components=13,\n",
        "                         k=3,\n",
        "                         n=11,\n",
        "                         learning_schedule=\"adagrad\",\n",
        "                         loss=\"warp-kos\",\n",
        "                         learning_rate=0.027,\n",
        "                         item_alpha=0.00001,\n",
        "                         user_alpha=0.00014,\n",
        "                         max_sampled=42)\n",
        "\n",
        "model_warp_kos.fit(train_local_csr, epochs=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Acma2xU-no0A",
        "outputId": "e5096de5-dc0a-4270-a9a0-278085287850"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<lightfm.lightfm.LightFM at 0x7fe6240439a0>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(model_warp_kos, open(\"model_warp_kos.pkl\", \"wb\"))"
      ],
      "metadata": {
        "id": "kfzMN_eaYWLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Из обученных моделей достаём для топ N айтемов с наибольшим скором для каждого юзера item_id, ранг и скор. Вычисление скора является крайне трудоёмким процессом, поэтому скоры были предпосчитаны заранее. Для этого использовалась функция:"
      ],
      "metadata": {
        "id": "ueTRMs0GnryD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "На основании скоров функции выше сможем проранжировать кандидатов каждой модели"
      ],
      "metadata": {
        "id": "TW4vKXg0orTA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def scores_calculation(user_embeddings, item_embeddings, user_biases, item_biases, items_number=50, top=50):\n",
        "\n",
        "  first_N_scores = user_embeddings.dot(item_embeddings[:items_number].T) + user_biases.reshape(-1,1) + item_biases[:items_number].reshape(1,-1)\n",
        "\n",
        "  pairs = list()\n",
        "\n",
        "  # Пронумеруем первые N айтемов, чтобы не потеряться в нумерации, ведь она не совпадает с исходными item_id\n",
        "  for i in range(len(first_N_scores)):\n",
        "    user_scores = list()\n",
        "    for elem in enumerate(first_N_scores[i]):\n",
        "      user_scores.append(elem)\n",
        "    pairs.append(user_scores)\n",
        "\n",
        "  # Отберём N (=items_number) айтемов с наибольшим скором, которые и будут кандидатами от модели\n",
        "  for u in tqdm(range(len(user_embeddings))):\n",
        "    for i in range(top, len(item_embeddings)):\n",
        "      score = list(user_embeddings[u:(u + 1)].dot(item_embeddings[i:(i+1)].T) + user_biases[:1].reshape(-1,1) + item_biases[i:(i+1)].reshape(1,-1))[0][0]\n",
        "      pair = (i, score)\n",
        "      pairs[u].append(pair)\n",
        "      pairs[u] = sorted(pairs[u], key=lambda x: x[-1], reverse=True)\n",
        "      pairs[u].remove(pairs[u][-1])\n",
        "\n",
        "  return pairs"
      ],
      "metadata": {
        "id": "wchDmDE_N8gM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def candidates_extraction(model_type, users_test, items_test, top=50, precomputed_scores=True):\n",
        "\n",
        "  if precomputed_scores == True:\n",
        "    path = \"/content/drive/MyDrive/WB School/pairs\" + \"_\" + model_type + \".npy\"\n",
        "    pairs = load(path)\n",
        "    pairs = pairs[:]\n",
        "  elif precomputed_scores == False:\n",
        "    path_item_emb = \"/content/drive/MyDrive/WB School/item_emb_\" + model_type + \".npy\"\n",
        "    path_user_emb = \"/content/drive/MyDrive/WB School/user_emb_\" + model_type + \".npy\"\n",
        "    path_user_bias = \"/content/drive/MyDrive/WB School/user_biases_\" + model_type + \".npy\"\n",
        "    path_item_bias = \"/content/drive/MyDrive/WB School/item_biases_\" + model_type + \".npy\"\n",
        "\n",
        "    item_emb = load(path_item_emb)\n",
        "    user_emb = load(path_user_emb)\n",
        "    user_biases = load(path_user_bias)\n",
        "    item_biases = load(path_item_bias)\n",
        "\n",
        "    pairs = scores_calculation(user_emb, item_emb, user_biases, item_biases, items_number=50)\n",
        "\n",
        "  model_dict = dict()\n",
        "  for user, user_data in enumerate(pairs):\n",
        "        for rank, (item, score) in enumerate(user_data):\n",
        "            key = tuple([user, item])\n",
        "            value = tuple([score, (rank + 1)])\n",
        "            model_dict[key] = value\n",
        "\n",
        "  model_pairs = list()\n",
        "  for key in model_dict.keys():\n",
        "      model_pairs.append(key)\n",
        "\n",
        "  return model_pairs, model_dict"
      ],
      "metadata": {
        "id": "4HBAo6RtpiM9"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_test = sorted(list(set(coo_matrix(train_local_csr).row)))\n",
        "items_test = sorted(list(set(coo_matrix(train_local_csr).col)))"
      ],
      "metadata": {
        "id": "4_-evE9lwpqn"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Некоторые переменные больше не нужны"
      ],
      "metadata": {
        "id": "fNhngGper5ak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del train_local\n",
        "del df\n",
        "del train_local_grouped\n",
        "del test_local_grouped\n",
        "del all_items\n",
        "del users_final\n",
        "del train_local_csr\n",
        "# del model_warp\n",
        "# del user_biases_warp\n",
        "# del item_biases_warp\n",
        "# del item_emb_warp\n",
        "# del user_emb_warp\n",
        "del df_new\n",
        "del train_global"
      ],
      "metadata": {
        "id": "YwPJx20wr44Y"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "warp_pairs, warp_dict = candidates_extraction(\"warp_new\", users_test, items_test, top=50, precomputed_scores=True) # 3.6 GB\n",
        "bpr_pairs, bpr_dict = candidates_extraction(\"bpr_new\", users_test, items_test, top=50, precomputed_scores=True) # 3.9 GB\n",
        "# lmf_pairs, lmf_dict, lmf_user_biases_series, lmf_item_biases_series, lmf_user_emb = candidates_extraction(model_lmf, \"lmf\", users_test, items_test, top=50, precomputed_scores=True)\n",
        "# warp_kos_pairs, warp_kos_dict = candidates_extraction(\"warp_kos\", users_test, items_test, top=50, precomputed_scores=True)"
      ],
      "metadata": {
        "id": "OLDxT7-OrW83"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Собираем из этого датасет."
      ],
      "metadata": {
        "id": "81VVxG4erm_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total_pairs = list(set(warp_pairs).union(set(bpr_pairs)))\n",
        "# total_pairs = list(set(total_pairs).union(set(lmf_pairs)))\n",
        "# total_pairs = list(set(total_pairs).union(set(warp_kos_pairs)))"
      ],
      "metadata": {
        "id": "ZrSmg4TZyO34"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del warp_pairs\n",
        "del bpr_pairs\n",
        "# del lmf_pairs\n",
        "# del warp_kos_pairs"
      ],
      "metadata": {
        "id": "XIPW8Julyd_5"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_all_pairs = [pair +\n",
        "                  warp_dict.get(pair, (np.nan, np.nan)) +\n",
        "                  bpr_dict.get(pair, (np.nan, np.nan))  for pair in tqdm(total_pairs)]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y7ZuIW6Iq2Pu",
        "outputId": "ce8b6873-8520-4d5e-8caa-66d579c8458d"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 17666447/17666447 [00:51<00:00, 344797.51it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del warp_dict\n",
        "del bpr_dict\n",
        "# del lmf_dict\n",
        "# del warp_kos_dict"
      ],
      "metadata": {
        "id": "kama5xfjYnMu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_all_pairs_df = pd.DataFrame(data_all_pairs,\n",
        "                                 columns=[\"user_id\", \"item_id\", \"warp_score\", \"warp_rank\",\n",
        "                                                                \"bpr_score\", \"bpr_rank\"])"
      ],
      "metadata": {
        "id": "pS0kRwpDrtZh"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del data_all_pairs"
      ],
      "metadata": {
        "id": "eTYNGlg0ruzv"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "При подгрузке предпосчитанных скоров из-за формата .npy меняется тип данных, поэтому зададим формат в ручную:"
      ],
      "metadata": {
        "id": "Rxh03R9Aq0b3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def change_dtype(df):\n",
        "\n",
        "    for column in df.columns:\n",
        "        if column.endswith(\"id\"):\n",
        "            df[column] = df[column].astype(np.int32)\n",
        "        else:\n",
        "            df[column] = df[column].astype(np.float32)\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "zng_hb6ssSMH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_all_pairs_df = change_dtype(data_all_pairs_df)"
      ],
      "metadata": {
        "id": "Iq4lDmUUsUz2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Заполним пропуски, чтобы бустинг мог работать"
      ],
      "metadata": {
        "id": "1heGVaiSsf42"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fill_nans(df, top):\n",
        "\n",
        "    for column in df.columns:\n",
        "        if column.endswith(\"score\"):\n",
        "            df[column] = df[column].fillna(random.uniform(0, 1))\n",
        "        elif column.endswith(\"rank\"):\n",
        "            df[column] = df[column].fillna(random.randint(top, (top + 100))) # Чтобы отдалить незаказанные айтемы\n",
        "\n",
        "    return df"
      ],
      "metadata": {
        "id": "I5Q-mPsBsWqG"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = fill_nans(data_all_pairs_df, top=50)"
      ],
      "metadata": {
        "id": "UAb9n_kNse7f"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Моделью II-го уровня будет градиентный бустинг. Он перешёл в задачу ранжирования из задачи (бинарной) классификации, поэтому необходимо собрать таргет из 0 и 1, где 1 будет означать, что юзер заказал айтем.\n",
        "\n",
        "В словарь purchases сложим все покупки юзеров в тестовом периоде."
      ],
      "metadata": {
        "id": "VIryn4AJsuYW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "purchases = list()\n",
        "\n",
        "for k in tqdm(range(test_local_csr.shape[0])):\n",
        "    cx = coo_matrix(test_local_csr[k])\n",
        "    purchased_items, user_id = [], []\n",
        "    user_id.append(k)\n",
        "\n",
        "    for i,j,v in zip(cx.row, cx.col, cx.data):\n",
        "        purchased_items.append(j)\n",
        "    for i in list(itertools.product(user_id, purchased_items)):\n",
        "        purchases.append(i)"
      ],
      "metadata": {
        "id": "Pw7PTvEWsvPV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8f1563c6-bb26-4874-b631-15f801037b4b"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 224642/224642 [00:59<00:00, 3791.70it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def purchases2dict(purchases):\n",
        "\n",
        "    data_true = {}\n",
        "    for i in tqdm(purchases):\n",
        "        curr, item = i[0], int(i[1])\n",
        "\n",
        "        if curr not in data_true:\n",
        "            data_true[curr] = list()\n",
        "            data_true[curr].append(item)\n",
        "        else:\n",
        "            data_true[curr].append(item)\n",
        "\n",
        "    for i in tqdm(data_true.keys()):\n",
        "        data_true[i] = set(data_true[i])\n",
        "\n",
        "    return data_true"
      ],
      "metadata": {
        "id": "ib9Mh-O4s24q"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_true = purchases2dict(purchases)"
      ],
      "metadata": {
        "id": "mvJibpb9tWRI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ce688cd-f1ba-4cf4-e440-ec280db7c083"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1661221/1661221 [00:05<00:00, 292918.38it/s]\n",
            "100%|██████████| 224642/224642 [00:03<00:00, 71179.21it/s] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del purchases"
      ],
      "metadata": {
        "id": "hJ_BZEvcP5xY"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Вернём исходные идентификаторы айтемам и юзерам, которые преобразовывали для обучения моделей"
      ],
      "metadata": {
        "id": "hkpYzygRtb4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "items_dict = dict(zip(train.item_new_id, train.item_id))\n",
        "users_dict = dict(zip(train.user_new_id, train.user_id))"
      ],
      "metadata": {
        "id": "A8lAMWE4tc8v"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[\"user_id\"] = predictions[\"user_id\"].map(users_dict)\n",
        "predictions[\"item_id\"] = predictions[\"item_id\"].map(items_dict)"
      ],
      "metadata": {
        "id": "iFuA9G5Kti2Q"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del items_dict\n",
        "del users_dict"
      ],
      "metadata": {
        "id": "gqoVeVZqQMGA"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del train"
      ],
      "metadata": {
        "id": "w6LJuprDYxpx"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сделаем привычный для бустинга датасет"
      ],
      "metadata": {
        "id": "KgYg12Rdtsrx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test[\"target\"] = 1\n",
        "\n",
        "dataset = pd.merge(predictions,\n",
        "                   test[[\"user_id\", \"item_id\", \"target\"]].drop_duplicates(),\n",
        "                   how=\"left\",\n",
        "                   left_on=[\"user_id\", \"item_id\"],\n",
        "                   right_on=[\"user_id\", \"item_id\"])\n",
        "\n",
        "dataset[\"target\"].fillna(0, inplace=True)"
      ],
      "metadata": {
        "id": "k0tTAluVtjX_"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del predictions"
      ],
      "metadata": {
        "id": "sHKStOVjQgjQ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.dropna()"
      ],
      "metadata": {
        "id": "6gETI7LFtx-Y"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.target.value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0VtMhELQwUg",
        "outputId": "1eea0bf1-77f3-46fa-f39f-f5d57361f175"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    0.961707\n",
              "1.0    0.038293\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FW9peZImQo-x",
        "outputId": "8448e1f9-d7e8-4f9c-deca-3e729f3c12a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   user_id  item_id  warp_score  warp_rank  bpr_score  bpr_rank  target\n",
              "0   608003      407    0.785074      143.0   0.023496      36.0     0.0\n",
              "1    31409       82    1.585430       24.0   0.041741      19.0     0.0\n",
              "2   620822     1069    1.595243       42.0   0.542877     145.0     1.0\n",
              "3   520135      347    1.424931       34.0   0.542877     145.0     0.0\n",
              "4   852904      180    1.853096       11.0   0.069260      10.0     1.0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1a14c063-ebb1-4b80-8cac-a6d76dd56378\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>item_id</th>\n",
              "      <th>warp_score</th>\n",
              "      <th>warp_rank</th>\n",
              "      <th>bpr_score</th>\n",
              "      <th>bpr_rank</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>608003</td>\n",
              "      <td>407</td>\n",
              "      <td>0.785074</td>\n",
              "      <td>143.0</td>\n",
              "      <td>0.023496</td>\n",
              "      <td>36.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>31409</td>\n",
              "      <td>82</td>\n",
              "      <td>1.585430</td>\n",
              "      <td>24.0</td>\n",
              "      <td>0.041741</td>\n",
              "      <td>19.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>620822</td>\n",
              "      <td>1069</td>\n",
              "      <td>1.595243</td>\n",
              "      <td>42.0</td>\n",
              "      <td>0.542877</td>\n",
              "      <td>145.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>520135</td>\n",
              "      <td>347</td>\n",
              "      <td>1.424931</td>\n",
              "      <td>34.0</td>\n",
              "      <td>0.542877</td>\n",
              "      <td>145.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>852904</td>\n",
              "      <td>180</td>\n",
              "      <td>1.853096</td>\n",
              "      <td>11.0</td>\n",
              "      <td>0.069260</td>\n",
              "      <td>10.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1a14c063-ebb1-4b80-8cac-a6d76dd56378')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1a14c063-ebb1-4b80-8cac-a6d76dd56378 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1a14c063-ebb1-4b80-8cac-a6d76dd56378');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обычным для бустинга отделим таргет и данные"
      ],
      "metadata": {
        "id": "laiSTGZnuFNY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Y = dataset.pop(\"target\")\n",
        "X = dataset"
      ],
      "metadata": {
        "id": "t4uGdqWouCd3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.7, random_state=42)\n",
        "\n",
        "X_train = x_train[[\"warp_score\", \"warp_rank\", \"bpr_score\", \"bpr_rank\"]]\n",
        "X_test = x_test[[\"warp_score\", \"warp_rank\", \"bpr_score\", \"bpr_rank\"]]\n",
        "train_data, test_data = lightgbm.Dataset(X_train, y_train), lightgbm.Dataset(X_test, y_test)"
      ],
      "metadata": {
        "id": "1T8HY6WOuHkv"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Для кросс-валидации вместо такого деления на train/test надо разбить на K фолдов и на них подбирать оптимальные параметры бустинга."
      ],
      "metadata": {
        "id": "0tZimP4zuMu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "del X\n",
        "del Y\n",
        "del x_train, y_train\n",
        "del X_train, X_test\n",
        "del dataset"
      ],
      "metadata": {
        "id": "M-K6BCxGRFEx"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Ранжирование"
      ],
      "metadata": {
        "id": "3jOSIdf3v7zn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Обучим модель градиентного бустинга:"
      ],
      "metadata": {
        "id": "nNysyN_dwBeH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\"objective\": \"binary\",\n",
        "          \"boosting\": \"gbdt\",\n",
        "          \"metric\": \"binary_logloss\",\n",
        "          \"verbose\": 1,\n",
        "          \"learning_rate\": 0.001}\n",
        "\n",
        "model = lightgbm.train(params,\n",
        "                       train_data,\n",
        "                       valid_sets=test_data,\n",
        "                       num_boost_round=200,\n",
        "                       verbose_eval=1)"
      ],
      "metadata": {
        "id": "cgL5YBOOv38o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf950293-b901-48a6-e1c1-67ab5ec10db6"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n",
            "  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 473018, number of negative: 11893494\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 1.081626 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 614\n",
            "[LightGBM] [Info] Number of data points in the train set: 12366512, number of used features: 4\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.038250 -> initscore=-3.224613\n",
            "[LightGBM] [Info] Start training from score -3.224613\n",
            "[1]\tvalid_0's binary_logloss: 0.16278\n",
            "[2]\tvalid_0's binary_logloss: 0.162751\n",
            "[3]\tvalid_0's binary_logloss: 0.162721\n",
            "[4]\tvalid_0's binary_logloss: 0.162692\n",
            "[5]\tvalid_0's binary_logloss: 0.162663\n",
            "[6]\tvalid_0's binary_logloss: 0.162634\n",
            "[7]\tvalid_0's binary_logloss: 0.162605\n",
            "[8]\tvalid_0's binary_logloss: 0.162576\n",
            "[9]\tvalid_0's binary_logloss: 0.162547\n",
            "[10]\tvalid_0's binary_logloss: 0.162518\n",
            "[11]\tvalid_0's binary_logloss: 0.16249\n",
            "[12]\tvalid_0's binary_logloss: 0.162461\n",
            "[13]\tvalid_0's binary_logloss: 0.162433\n",
            "[14]\tvalid_0's binary_logloss: 0.162405\n",
            "[15]\tvalid_0's binary_logloss: 0.162376\n",
            "[16]\tvalid_0's binary_logloss: 0.162348\n",
            "[17]\tvalid_0's binary_logloss: 0.16232\n",
            "[18]\tvalid_0's binary_logloss: 0.162292\n",
            "[19]\tvalid_0's binary_logloss: 0.162265\n",
            "[20]\tvalid_0's binary_logloss: 0.162237\n",
            "[21]\tvalid_0's binary_logloss: 0.162209\n",
            "[22]\tvalid_0's binary_logloss: 0.162182\n",
            "[23]\tvalid_0's binary_logloss: 0.162154\n",
            "[24]\tvalid_0's binary_logloss: 0.162127\n",
            "[25]\tvalid_0's binary_logloss: 0.162099\n",
            "[26]\tvalid_0's binary_logloss: 0.162072\n",
            "[27]\tvalid_0's binary_logloss: 0.162045\n",
            "[28]\tvalid_0's binary_logloss: 0.162018\n",
            "[29]\tvalid_0's binary_logloss: 0.161991\n",
            "[30]\tvalid_0's binary_logloss: 0.161964\n",
            "[31]\tvalid_0's binary_logloss: 0.161937\n",
            "[32]\tvalid_0's binary_logloss: 0.161911\n",
            "[33]\tvalid_0's binary_logloss: 0.161884\n",
            "[34]\tvalid_0's binary_logloss: 0.161857\n",
            "[35]\tvalid_0's binary_logloss: 0.161831\n",
            "[36]\tvalid_0's binary_logloss: 0.161805\n",
            "[37]\tvalid_0's binary_logloss: 0.161778\n",
            "[38]\tvalid_0's binary_logloss: 0.161752\n",
            "[39]\tvalid_0's binary_logloss: 0.161726\n",
            "[40]\tvalid_0's binary_logloss: 0.1617\n",
            "[41]\tvalid_0's binary_logloss: 0.161674\n",
            "[42]\tvalid_0's binary_logloss: 0.161648\n",
            "[43]\tvalid_0's binary_logloss: 0.161622\n",
            "[44]\tvalid_0's binary_logloss: 0.161596\n",
            "[45]\tvalid_0's binary_logloss: 0.161571\n",
            "[46]\tvalid_0's binary_logloss: 0.161545\n",
            "[47]\tvalid_0's binary_logloss: 0.161519\n",
            "[48]\tvalid_0's binary_logloss: 0.161494\n",
            "[49]\tvalid_0's binary_logloss: 0.161469\n",
            "[50]\tvalid_0's binary_logloss: 0.161443\n",
            "[51]\tvalid_0's binary_logloss: 0.161418\n",
            "[52]\tvalid_0's binary_logloss: 0.161392\n",
            "[53]\tvalid_0's binary_logloss: 0.161367\n",
            "[54]\tvalid_0's binary_logloss: 0.161342\n",
            "[55]\tvalid_0's binary_logloss: 0.161317\n",
            "[56]\tvalid_0's binary_logloss: 0.161292\n",
            "[57]\tvalid_0's binary_logloss: 0.161267\n",
            "[58]\tvalid_0's binary_logloss: 0.161242\n",
            "[59]\tvalid_0's binary_logloss: 0.161217\n",
            "[60]\tvalid_0's binary_logloss: 0.161192\n",
            "[61]\tvalid_0's binary_logloss: 0.161168\n",
            "[62]\tvalid_0's binary_logloss: 0.161143\n",
            "[63]\tvalid_0's binary_logloss: 0.161118\n",
            "[64]\tvalid_0's binary_logloss: 0.161094\n",
            "[65]\tvalid_0's binary_logloss: 0.16107\n",
            "[66]\tvalid_0's binary_logloss: 0.161045\n",
            "[67]\tvalid_0's binary_logloss: 0.161021\n",
            "[68]\tvalid_0's binary_logloss: 0.160997\n",
            "[69]\tvalid_0's binary_logloss: 0.160973\n",
            "[70]\tvalid_0's binary_logloss: 0.160949\n",
            "[71]\tvalid_0's binary_logloss: 0.160925\n",
            "[72]\tvalid_0's binary_logloss: 0.160901\n",
            "[73]\tvalid_0's binary_logloss: 0.160877\n",
            "[74]\tvalid_0's binary_logloss: 0.160853\n",
            "[75]\tvalid_0's binary_logloss: 0.160829\n",
            "[76]\tvalid_0's binary_logloss: 0.160805\n",
            "[77]\tvalid_0's binary_logloss: 0.160782\n",
            "[78]\tvalid_0's binary_logloss: 0.160758\n",
            "[79]\tvalid_0's binary_logloss: 0.160735\n",
            "[80]\tvalid_0's binary_logloss: 0.160711\n",
            "[81]\tvalid_0's binary_logloss: 0.160688\n",
            "[82]\tvalid_0's binary_logloss: 0.160665\n",
            "[83]\tvalid_0's binary_logloss: 0.160641\n",
            "[84]\tvalid_0's binary_logloss: 0.160618\n",
            "[85]\tvalid_0's binary_logloss: 0.160595\n",
            "[86]\tvalid_0's binary_logloss: 0.160572\n",
            "[87]\tvalid_0's binary_logloss: 0.160549\n",
            "[88]\tvalid_0's binary_logloss: 0.160526\n",
            "[89]\tvalid_0's binary_logloss: 0.160503\n",
            "[90]\tvalid_0's binary_logloss: 0.16048\n",
            "[91]\tvalid_0's binary_logloss: 0.160458\n",
            "[92]\tvalid_0's binary_logloss: 0.160435\n",
            "[93]\tvalid_0's binary_logloss: 0.160412\n",
            "[94]\tvalid_0's binary_logloss: 0.16039\n",
            "[95]\tvalid_0's binary_logloss: 0.160367\n",
            "[96]\tvalid_0's binary_logloss: 0.160345\n",
            "[97]\tvalid_0's binary_logloss: 0.160322\n",
            "[98]\tvalid_0's binary_logloss: 0.1603\n",
            "[99]\tvalid_0's binary_logloss: 0.160278\n",
            "[100]\tvalid_0's binary_logloss: 0.160256\n",
            "[101]\tvalid_0's binary_logloss: 0.160233\n",
            "[102]\tvalid_0's binary_logloss: 0.160211\n",
            "[103]\tvalid_0's binary_logloss: 0.160189\n",
            "[104]\tvalid_0's binary_logloss: 0.160167\n",
            "[105]\tvalid_0's binary_logloss: 0.160145\n",
            "[106]\tvalid_0's binary_logloss: 0.160124\n",
            "[107]\tvalid_0's binary_logloss: 0.160102\n",
            "[108]\tvalid_0's binary_logloss: 0.16008\n",
            "[109]\tvalid_0's binary_logloss: 0.160058\n",
            "[110]\tvalid_0's binary_logloss: 0.160037\n",
            "[111]\tvalid_0's binary_logloss: 0.160015\n",
            "[112]\tvalid_0's binary_logloss: 0.159994\n",
            "[113]\tvalid_0's binary_logloss: 0.159972\n",
            "[114]\tvalid_0's binary_logloss: 0.159951\n",
            "[115]\tvalid_0's binary_logloss: 0.159929\n",
            "[116]\tvalid_0's binary_logloss: 0.159908\n",
            "[117]\tvalid_0's binary_logloss: 0.159887\n",
            "[118]\tvalid_0's binary_logloss: 0.159866\n",
            "[119]\tvalid_0's binary_logloss: 0.159845\n",
            "[120]\tvalid_0's binary_logloss: 0.159824\n",
            "[121]\tvalid_0's binary_logloss: 0.159803\n",
            "[122]\tvalid_0's binary_logloss: 0.159782\n",
            "[123]\tvalid_0's binary_logloss: 0.159761\n",
            "[124]\tvalid_0's binary_logloss: 0.15974\n",
            "[125]\tvalid_0's binary_logloss: 0.159719\n",
            "[126]\tvalid_0's binary_logloss: 0.159698\n",
            "[127]\tvalid_0's binary_logloss: 0.159678\n",
            "[128]\tvalid_0's binary_logloss: 0.159657\n",
            "[129]\tvalid_0's binary_logloss: 0.159636\n",
            "[130]\tvalid_0's binary_logloss: 0.159616\n",
            "[131]\tvalid_0's binary_logloss: 0.159595\n",
            "[132]\tvalid_0's binary_logloss: 0.159575\n",
            "[133]\tvalid_0's binary_logloss: 0.159555\n",
            "[134]\tvalid_0's binary_logloss: 0.159534\n",
            "[135]\tvalid_0's binary_logloss: 0.159514\n",
            "[136]\tvalid_0's binary_logloss: 0.159494\n",
            "[137]\tvalid_0's binary_logloss: 0.159474\n",
            "[138]\tvalid_0's binary_logloss: 0.159453\n",
            "[139]\tvalid_0's binary_logloss: 0.159433\n",
            "[140]\tvalid_0's binary_logloss: 0.159413\n",
            "[141]\tvalid_0's binary_logloss: 0.159393\n",
            "[142]\tvalid_0's binary_logloss: 0.159374\n",
            "[143]\tvalid_0's binary_logloss: 0.159354\n",
            "[144]\tvalid_0's binary_logloss: 0.159334\n",
            "[145]\tvalid_0's binary_logloss: 0.159314\n",
            "[146]\tvalid_0's binary_logloss: 0.159294\n",
            "[147]\tvalid_0's binary_logloss: 0.159275\n",
            "[148]\tvalid_0's binary_logloss: 0.159255\n",
            "[149]\tvalid_0's binary_logloss: 0.159235\n",
            "[150]\tvalid_0's binary_logloss: 0.159216\n",
            "[151]\tvalid_0's binary_logloss: 0.159196\n",
            "[152]\tvalid_0's binary_logloss: 0.159177\n",
            "[153]\tvalid_0's binary_logloss: 0.159158\n",
            "[154]\tvalid_0's binary_logloss: 0.159138\n",
            "[155]\tvalid_0's binary_logloss: 0.159119\n",
            "[156]\tvalid_0's binary_logloss: 0.1591\n",
            "[157]\tvalid_0's binary_logloss: 0.15908\n",
            "[158]\tvalid_0's binary_logloss: 0.159061\n",
            "[159]\tvalid_0's binary_logloss: 0.159042\n",
            "[160]\tvalid_0's binary_logloss: 0.159023\n",
            "[161]\tvalid_0's binary_logloss: 0.159004\n",
            "[162]\tvalid_0's binary_logloss: 0.158985\n",
            "[163]\tvalid_0's binary_logloss: 0.158966\n",
            "[164]\tvalid_0's binary_logloss: 0.158947\n",
            "[165]\tvalid_0's binary_logloss: 0.158928\n",
            "[166]\tvalid_0's binary_logloss: 0.158909\n",
            "[167]\tvalid_0's binary_logloss: 0.158891\n",
            "[168]\tvalid_0's binary_logloss: 0.158872\n",
            "[169]\tvalid_0's binary_logloss: 0.158853\n",
            "[170]\tvalid_0's binary_logloss: 0.158835\n",
            "[171]\tvalid_0's binary_logloss: 0.158816\n",
            "[172]\tvalid_0's binary_logloss: 0.158797\n",
            "[173]\tvalid_0's binary_logloss: 0.158779\n",
            "[174]\tvalid_0's binary_logloss: 0.15876\n",
            "[175]\tvalid_0's binary_logloss: 0.158742\n",
            "[176]\tvalid_0's binary_logloss: 0.158724\n",
            "[177]\tvalid_0's binary_logloss: 0.158705\n",
            "[178]\tvalid_0's binary_logloss: 0.158687\n",
            "[179]\tvalid_0's binary_logloss: 0.158669\n",
            "[180]\tvalid_0's binary_logloss: 0.15865\n",
            "[181]\tvalid_0's binary_logloss: 0.158632\n",
            "[182]\tvalid_0's binary_logloss: 0.158614\n",
            "[183]\tvalid_0's binary_logloss: 0.158596\n",
            "[184]\tvalid_0's binary_logloss: 0.158578\n",
            "[185]\tvalid_0's binary_logloss: 0.15856\n",
            "[186]\tvalid_0's binary_logloss: 0.158542\n",
            "[187]\tvalid_0's binary_logloss: 0.158524\n",
            "[188]\tvalid_0's binary_logloss: 0.158506\n",
            "[189]\tvalid_0's binary_logloss: 0.158488\n",
            "[190]\tvalid_0's binary_logloss: 0.158471\n",
            "[191]\tvalid_0's binary_logloss: 0.158453\n",
            "[192]\tvalid_0's binary_logloss: 0.158435\n",
            "[193]\tvalid_0's binary_logloss: 0.158418\n",
            "[194]\tvalid_0's binary_logloss: 0.1584\n",
            "[195]\tvalid_0's binary_logloss: 0.158382\n",
            "[196]\tvalid_0's binary_logloss: 0.158365\n",
            "[197]\tvalid_0's binary_logloss: 0.158347\n",
            "[198]\tvalid_0's binary_logloss: 0.15833\n",
            "[199]\tvalid_0's binary_logloss: 0.158312\n",
            "[200]\tvalid_0's binary_logloss: 0.158295\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lgb_test = x_test.copy()\n",
        "lgb_test[[\"user_id\", \"item_id\"]].drop_duplicates(inplace=True)\n",
        "lgb_test.set_index([\"user_id\", \"item_id\"], inplace=True)\n",
        "lgb_test[\"lgb_score\"] = model.predict(lgb_test, num_iteration=model.best_iteration)\n",
        "lgb_test = lgb_test.set_index(\"lgb_score\", append=True).sort_values(\"lgb_score\", ascending=False)\n",
        "lgb_test.drop_duplicates(inplace=True)\n",
        "\n",
        "dataset_predicted = dict()\n",
        "lgb_test.reset_index(inplace=True)\n",
        "for user, group in tqdm(lgb_test.groupby(\"user_id\")):\n",
        "    dataset_predicted[user] = list(group.item_id)[:20]"
      ],
      "metadata": {
        "id": "1dvlecZ9wKi_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbc030ba-6239-425e-c93b-01ceb840c52f"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-8ed49ef528dd>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  lgb_test[[\"user_id\", \"item_id\"]].drop_duplicates(inplace=True)\n",
            "100%|██████████| 224642/224642 [00:20<00:00, 11124.07it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from numpy import save"
      ],
      "metadata": {
        "id": "Cp3Qj6UDehVr"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save(\"dataset_predicted_new.npy\", dataset_predicted, allow_pickle=True)"
      ],
      "metadata": {
        "id": "eIzyc7MSeKdC"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('dataset_predicted.pkl', 'wb') as f:\n",
        "    pickle.dump(dataset_predicted, f)"
      ],
      "metadata": {
        "id": "VOTVxQLgepuk"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/drive/MyDrive/WB School/dataset_predicted.pkl', 'rb') as f:\n",
        "    dataset_predicted = pickle.load(f)"
      ],
      "metadata": {
        "id": "KgUR_HOMhYGj"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Источники #\n",
        "\n",
        "1. Гибрид, идея train/test сплит:\n",
        "[A Hybrid Approach to Music Playlist Continuation Based on Playlist-Song Membership](https://arxiv.org/abs/1805.09557).\n",
        "\n",
        "2. Hybrid model have lower Precision@K compare to pure CF: Issue on [Github](https://github.com/lyst/lightfm/issues/486)\n",
        "\n",
        "3. Weston, Jason, Samy Bengio, and Nicolas Usunier. “Wsabie: Scaling up to large vocabulary image annotation.” IJCAI. Vol. 11. 2011.\n",
        "https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/37180.pdf\n",
        "\n",
        "4. Weston, J., Yee, H., & Weiss, R. J. (2013, October). Learning to rank recommendations with the k-order statistic loss. In Proceedings of the 7th ACM Conference on Recommender Systems (pp. 245-248). [dl.acm.org](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/41534.pdf)\n",
        "\n",
        "\n",
        "5. Rendle, Steffen, et al. “BPR: Bayesian personalized ranking from implicit feedback.” Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. AUAI Press, 2009. [arxiv.org](https://arxiv.org/ftp/arxiv/papers/1205/1205.2618.pdf)\n",
        "\n",
        "6. Johnson, C. C. (2014). Logistic matrix factorization for implicit feedback data. Advances in Neural Information Processing Systems, 27(78), 1-9. [stanford.edu](https://web.stanford.edu/~rezab/nips2014workshop/submits/logmat.pdf)\n",
        "\n",
        "7. Ben Frederickson. Distance Metrics for Fun and Profit. [Блог об implicit](https://www.benfrederickson.com/distance-metrics/)"
      ],
      "metadata": {
        "id": "9LgJvqPplT9r"
      }
    }
  ]
}